{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python -m pip install pip==23.2\n",
    "^ this version worked for me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pip install gym-retro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pip install setuptools==65.5.0 \"wheel<0.40.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pip install gym==0.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.8/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.17.0 in ./.venv/lib/python3.8/site-packages (from opencv-python) (1.24.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in d:\\streetfighterrl\\env_3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: gym-retro in d:\\streetfighterrl\\env_3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in d:\\streetfighterrl\\env_3\\lib\\site-packages (from gym) (1.24.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\streetfighterrl\\env_3\\lib\\site-packages (from gym) (3.1.0)\n",
      "Requirement already satisfied: pyglet==1.*,>=1.3.2 in d:\\streetfighterrl\\env_3\\lib\\site-packages (from gym-retro) (1.5.29)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install gym gym-retro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take note of my versions^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import retro to play Street Fighter using a ROM\n",
    "import retro\n",
    "# Import time to slow down game\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m retro.import . # Run this from the roms folder, or where you have your game roms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts up the game environment\n",
    "env = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import environment base class for a wrapper \n",
    "from gym import Env \n",
    "# Import the space shapes for the environment\n",
    "from gym.spaces import MultiBinary, Box\n",
    "# Import numpy to calculate frame delta \n",
    "import numpy as np\n",
    "# Import opencv for grayscaling\n",
    "import cv2\n",
    "# Import matplotlib for plotting the image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom environment \n",
    "class StreetFighter(Env): # pass in basic env from above to preprocessing\n",
    "    def __init__(self):\n",
    "        super().__init__() # inherit from base env\n",
    "        # Specify action space and observation space \n",
    "        self.observation_space = Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8) # grayscaled frame, smaller amt of pixels\n",
    "        self.action_space = MultiBinary(12) # type of actions that can be taken\n",
    "        self.health = 144\n",
    "        self.enemy_health = 144\n",
    "        self.score = 0\n",
    "        self.matches_won = 0\n",
    "        self.continue_timer = 100\n",
    "        self.enemy_matches_won = 0\n",
    "        self.previous_action = np.zeros(12)\n",
    "        # Startup and instance of the game \n",
    "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis', use_restricted_actions=retro.Actions.FILTERED) # used to get valid button combos\n",
    "    \n",
    "    def reset(self): # restart\n",
    "        # Return the first frame \n",
    "        obs = self.game.reset()\n",
    "        obs = self.preprocess(obs) \n",
    "        self.previous_frame = obs # sets previous frame to current frame\n",
    "        \n",
    "        # Create a attribute to hold the score delta \n",
    "        self.score = 0 \n",
    "        return obs\n",
    "    \n",
    "    def preprocess(self, observation): # grayscale, resize\n",
    "        # Grayscaling \n",
    "        gray = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "        # Resize \n",
    "        resize = cv2.resize(gray, (84,84), interpolation=cv2.INTER_CUBIC)\n",
    "        # Add the channels value\n",
    "        channels = np.reshape(resize, (84,84,1))\n",
    "        return channels \n",
    "    \n",
    "    def reward_function(self, state, action):\n",
    "        # Extract variables\n",
    "        continuetimer = state['continuetimer']\n",
    "        enemy_matches_won = state['enemy_matches_won']\n",
    "        enemy_health = state['enemy_health']\n",
    "        health = state['health']\n",
    "        matches_won = state['matches_won']\n",
    "        score = state['score']\n",
    "\n",
    "        # Initialize reward\n",
    "        reward = 0\n",
    "\n",
    "        # Reward for increasing score each frame (scaled down to avoid excessively large rewards)\n",
    "        reward += score * 0.001  \n",
    "\n",
    "        # Reward for inflicting damage on the enemy, only if enemy_health is reduced\n",
    "        if enemy_health < self.enemy_health:\n",
    "            reward += (self.enemy_health - enemy_health) * 10\n",
    "\n",
    "        # Penalty for losing health (scaled so health loss gives a clear penalty)\n",
    "        if health < self.health:\n",
    "            reward -= (self.health - health) * 10\n",
    "\n",
    "        # Bonus if the player maintains health\n",
    "        reward += health * 0.05  \n",
    "\n",
    "        # Encourage the AI to win matches\n",
    "        if matches_won > self.matches_won:\n",
    "            reward += 200  # Winning a match should give a significant reward\n",
    "\n",
    "        # Penalize the AI if the enemy wins a match\n",
    "        if enemy_matches_won > self.enemy_matches_won:\n",
    "            reward -= 200\n",
    "\n",
    "        # Small positive reward to encourage efficient play (keeping the timer active)\n",
    "        reward += continuetimer * 0.01  \n",
    "\n",
    "        # Penalize the AI for taking actions that do not lead to damage dealt\n",
    "        if enemy_health == self.enemy_health and action != np.zeros(12):\n",
    "            reward -= 1\n",
    "\n",
    "\n",
    "        # Update previous states to enable frame-by-frame comparison\n",
    "        self.enemy_health = enemy_health\n",
    "        self.health = health\n",
    "        self.matches_won = matches_won\n",
    "        self.enemy_matches_won = enemy_matches_won\n",
    "        self.continue_timer = continuetimer\n",
    "        self.score = score\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    def step(self, action): # how do we process action\n",
    "        # Take a step \n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "        obs = self.preprocess(obs) \n",
    "\n",
    "        self.previous_action = action\n",
    "        \n",
    "        # Frame delta \n",
    "        frame_delta = obs - self.previous_frame # change in pixels (was dropped in final model of tutorial)\n",
    "        self.previous_frame = obs \n",
    "        \n",
    "        # Reshape the reward function\n",
    "        reward = self.reward_function(info, action)\n",
    "\n",
    "        return frame_delta, reward, done, info\n",
    "    \n",
    "    def render(self, *args, **kwargs): # unpack any args and kwargs from stable baseline\n",
    "        self.game.render()\n",
    "        \n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StreetFighter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.800000000000001\n",
      "8.3\n",
      "8.100000000000001\n",
      "8.100000000000001\n",
      "8.4\n",
      "8.200000000000001\n",
      "8.100000000000001\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.600000000000001\n",
      "8.5\n",
      "8.3\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.600000000000001\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.5\n",
      "8.4\n",
      "8.4\n",
      "8.200000000000001\n",
      "8.200000000000001\n",
      "8.5\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.5\n",
      "8.100000000000001\n",
      "8.3\n",
      "7.9\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.600000000000001\n",
      "8.200000000000001\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.0\n",
      "8.4\n",
      "8.0\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.600000000000001\n",
      "7.9\n",
      "7.9\n",
      "7.9\n",
      "8.4\n",
      "8.200000000000001\n",
      "8.200000000000001\n",
      "8.200000000000001\n",
      "8.4\n",
      "8.100000000000001\n",
      "7.9\n",
      "8.3\n",
      "7.9\n",
      "8.3\n",
      "8.100000000000001\n",
      "8.200000000000001\n",
      "8.5\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.100000000000001\n",
      "8.0\n",
      "8.200000000000001\n",
      "8.100000000000001\n",
      "8.200000000000001\n",
      "8.4\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.100000000000001\n",
      "8.100000000000001\n",
      "8.100000000000001\n",
      "8.4\n",
      "8.100000000000001\n",
      "8.100000000000001\n",
      "8.200000000000001\n",
      "8.0\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.5\n",
      "8.200000000000001\n",
      "8.200000000000001\n",
      "7.9\n",
      "8.3\n",
      "7.800000000000001\n",
      "8.4\n",
      "8.200000000000001\n",
      "8.4\n",
      "7.9\n",
      "8.5\n",
      "8.4\n",
      "8.200000000000001\n",
      "8.5\n",
      "8.200000000000001\n",
      "8.0\n",
      "8.5\n",
      "8.0\n",
      "8.0\n",
      "8.4\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.0\n",
      "8.5\n",
      "8.200000000000001\n",
      "8.4\n",
      "8.200000000000001\n",
      "8.200000000000001\n",
      "8.4\n",
      "7.9\n",
      "8.3\n",
      "8.600000000000001\n",
      "8.600000000000001\n",
      "8.100000000000001\n",
      "8.5\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.4\n",
      "8.100000000000001\n",
      "8.100000000000001\n",
      "8.200000000000001\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.100000000000001\n",
      "8.100000000000001\n",
      "8.4\n",
      "8.0\n",
      "8.100000000000001\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.3\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.200000000000001\n",
      "8.3\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.4\n",
      "8.3\n",
      "8.3\n",
      "8.0\n",
      "8.5\n",
      "8.3\n",
      "8.100000000000001\n",
      "8.100000000000001\n",
      "8.5\n",
      "8.3\n",
      "8.200000000000001\n",
      "8.4\n",
      "8.0\n",
      "8.3\n",
      "8.600000000000001\n",
      "8.100000000000001\n",
      "8.100000000000001\n",
      "8.3\n",
      "8.4\n",
      "8.3\n",
      "8.3\n",
      "7.9\n",
      "-212.70000000000002\n",
      "7.1\n",
      "7.1\n",
      "7.0\n",
      "7.2\n",
      "7.2\n",
      "7.2\n",
      "7.0\n",
      "7.4\n",
      "6.8\n",
      "7.3\n",
      "7.2\n",
      "6.9\n",
      "7.0\n",
      "7.2\n",
      "7.0\n",
      "6.9\n",
      "7.2\n",
      "7.1\n",
      "6.9\n",
      "7.2\n",
      "7.2\n",
      "7.3\n",
      "7.3\n",
      "6.8\n",
      "7.3\n",
      "7.1\n",
      "7.1\n",
      "7.1\n",
      "7.1\n",
      "6.9\n",
      "7.1\n",
      "7.1\n",
      "7.0\n",
      "7.2\n",
      "6.9\n",
      "6.8\n",
      "7.2\n",
      "7.4\n",
      "7.0\n",
      "7.1\n",
      "7.3\n",
      "7.1\n",
      "7.1\n",
      "7.2\n",
      "7.1\n",
      "7.0\n",
      "7.3\n",
      "7.1\n",
      "7.1\n",
      "6.9\n",
      "7.3\n",
      "7.0\n",
      "7.1\n",
      "7.0\n",
      "7.1\n",
      "7.2\n",
      "7.4\n",
      "7.3\n",
      "7.4\n",
      "7.1\n",
      "7.3\n",
      "7.3\n",
      "7.6000000000000005\n",
      "7.0\n",
      "7.1\n",
      "7.0\n",
      "7.3\n",
      "7.2\n",
      "7.2\n",
      "7.0\n",
      "7.0\n",
      "7.3\n",
      "7.1\n",
      "6.8\n",
      "7.1\n",
      "6.8\n",
      "7.2\n",
      "7.1\n",
      "7.2\n",
      "7.2\n",
      "7.1\n",
      "7.3\n",
      "7.1\n",
      "7.2\n",
      "7.2\n",
      "7.0\n",
      "6.8\n",
      "6.9\n",
      "7.2\n",
      "7.0\n",
      "7.2\n",
      "6.9\n",
      "7.2\n",
      "7.2\n",
      "7.0\n",
      "7.2\n",
      "7.3\n",
      "7.1\n",
      "7.4\n",
      "7.0\n",
      "7.3\n",
      "6.9\n",
      "6.9\n",
      "7.5\n",
      "7.0\n",
      "7.1\n",
      "7.2\n",
      "7.1\n",
      "7.0\n",
      "7.1\n",
      "6.9\n",
      "6.9\n",
      "7.2\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "7.4\n",
      "7.2\n",
      "7.2\n",
      "7.2\n",
      "7.0\n",
      "7.0\n",
      "6.9\n",
      "7.2\n",
      "6.9\n",
      "7.1\n",
      "6.8\n",
      "7.2\n",
      "7.1\n",
      "7.0\n",
      "7.1\n",
      "6.8\n",
      "6.9\n",
      "7.0\n",
      "6.9\n",
      "7.2\n",
      "7.3\n",
      "7.1\n",
      "7.1\n",
      "7.2\n",
      "7.1\n",
      "7.0\n",
      "7.1\n",
      "7.2\n",
      "7.2\n",
      "7.4\n",
      "7.1\n",
      "7.3\n",
      "7.2\n",
      "7.0\n",
      "7.0\n",
      "7.2\n",
      "7.2\n",
      "7.0\n",
      "7.5\n",
      "7.2\n",
      "7.0\n",
      "6.9\n",
      "7.3\n",
      "6.7\n",
      "7.0\n",
      "7.0\n",
      "7.4\n",
      "7.1\n",
      "7.2\n",
      "7.1\n",
      "7.4\n",
      "7.0\n",
      "7.3\n",
      "7.3\n",
      "7.0\n",
      "7.0\n",
      "7.2\n",
      "7.2\n",
      "7.2\n",
      "7.0\n",
      "7.5\n",
      "7.1\n",
      "7.0\n",
      "6.9\n",
      "7.0\n",
      "7.1\n",
      "6.9\n",
      "7.5\n",
      "7.1\n",
      "7.0\n",
      "7.1\n",
      "7.2\n",
      "7.1\n",
      "7.2\n",
      "7.2\n",
      "7.0\n",
      "7.1\n",
      "6.9\n",
      "7.2\n",
      "7.2\n",
      "7.2\n",
      "6.8\n",
      "7.2\n",
      "7.1\n",
      "367.2\n",
      "7.499999999999999\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.499999999999999\n",
      "7.3999999999999995\n",
      "7.199999999999999\n",
      "7.699999999999999\n",
      "7.3999999999999995\n",
      "7.699999999999999\n",
      "7.799999999999999\n",
      "7.699999999999999\n",
      "7.6\n",
      "7.6\n",
      "7.6\n",
      "7.3999999999999995\n",
      "7.799999999999999\n",
      "7.6\n",
      "7.699999999999999\n",
      "7.699999999999999\n",
      "7.699999999999999\n",
      "7.6\n",
      "7.3999999999999995\n",
      "7.3999999999999995\n",
      "7.499999999999999\n",
      "7.699999999999999\n",
      "7.299999999999999\n",
      "7.499999999999999\n",
      "7.699999999999999\n",
      "7.499999999999999\n",
      "7.499999999999999\n",
      "7.8999999999999995\n",
      "7.999999999999999\n",
      "7.3999999999999995\n",
      "7.6\n",
      "7.3999999999999995\n",
      "7.6\n",
      "7.8999999999999995\n",
      "7.299999999999999\n",
      "7.299999999999999\n",
      "7.6\n",
      "7.3999999999999995\n",
      "7.3999999999999995\n",
      "7.3999999999999995\n",
      "7.6\n",
      "7.699999999999999\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.3999999999999995\n",
      "7.499999999999999\n",
      "7.799999999999999\n",
      "7.8999999999999995\n",
      "7.299999999999999\n",
      "7.3999999999999995\n",
      "7.3999999999999995\n",
      "7.6\n",
      "7.499999999999999\n",
      "7.799999999999999\n",
      "7.6\n",
      "7.6\n",
      "7.6\n",
      "7.699999999999999\n",
      "7.3999999999999995\n",
      "7.6\n",
      "7.3999999999999995\n",
      "7.3999999999999995\n",
      "7.799999999999999\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.499999999999999\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.299999999999999\n",
      "7.699999999999999\n",
      "7.799999999999999\n",
      "7.699999999999999\n",
      "7.6\n",
      "7.6\n",
      "7.3999999999999995\n",
      "7.699999999999999\n",
      "7.699999999999999\n",
      "7.3999999999999995\n",
      "7.499999999999999\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.699999999999999\n",
      "7.8999999999999995\n",
      "8.1\n",
      "7.499999999999999\n",
      "7.8999999999999995\n",
      "7.799999999999999\n",
      "7.699999999999999\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.3999999999999995\n",
      "7.499999999999999\n",
      "7.8999999999999995\n",
      "7.6\n",
      "7.699999999999999\n",
      "7.6\n",
      "7.499999999999999\n",
      "7.699999999999999\n",
      "7.3999999999999995\n",
      "7.699999999999999\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.3999999999999995\n",
      "7.699999999999999\n",
      "7.699999999999999\n",
      "7.499999999999999\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.499999999999999\n",
      "7.699999999999999\n",
      "7.799999999999999\n",
      "7.699999999999999\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.6\n",
      "7.499999999999999\n",
      "7.8999999999999995\n",
      "7.6\n",
      "7.499999999999999\n",
      "7.3999999999999995\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.699999999999999\n",
      "7.499999999999999\n",
      "7.699999999999999\n",
      "7.799999999999999\n",
      "7.499999999999999\n",
      "7.299999999999999\n",
      "7.699999999999999\n",
      "7.299999999999999\n",
      "7.699999999999999\n",
      "7.699999999999999\n",
      "7.199999999999999\n",
      "7.6\n",
      "7.8999999999999995\n",
      "7.3999999999999995\n",
      "7.6\n",
      "7.8999999999999995\n",
      "7.6\n",
      "7.6\n",
      "7.799999999999999\n",
      "7.6\n",
      "7.6\n",
      "7.499999999999999\n",
      "7.699999999999999\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.6\n",
      "7.699999999999999\n",
      "7.499999999999999\n",
      "7.799999999999999\n",
      "7.6\n",
      "7.499999999999999\n",
      "7.3999999999999995\n",
      "7.6\n",
      "7.6\n",
      "7.6\n",
      "7.499999999999999\n",
      "7.6\n",
      "7.6\n",
      "7.699999999999999\n",
      "7.299999999999999\n",
      "7.3999999999999995\n",
      "7.999999999999999\n",
      "7.699999999999999\n",
      "7.6\n",
      "7.499999999999999\n",
      "7.799999999999999\n",
      "7.6\n",
      "7.6\n",
      "7.799999999999999\n",
      "7.799999999999999\n",
      "7.499999999999999\n",
      "7.499999999999999\n",
      "7.699999999999999\n",
      "7.699999999999999\n",
      "-233.5\n",
      "6.4\n",
      "6.5\n",
      "6.3\n",
      "6.5\n",
      "6.4\n",
      "6.3\n",
      "6.0\n",
      "6.1\n",
      "6.2\n",
      "6.5\n",
      "6.6\n",
      "6.2\n",
      "6.4\n",
      "6.6\n",
      "6.5\n",
      "6.7\n",
      "6.7\n",
      "6.4\n",
      "6.2\n",
      "6.4\n",
      "6.5\n",
      "6.2\n",
      "6.2\n",
      "6.7\n",
      "6.6\n",
      "6.5\n",
      "6.6\n",
      "6.5\n",
      "6.1\n",
      "6.5\n",
      "6.6\n",
      "6.2\n",
      "6.4\n",
      "6.3\n",
      "6.4\n",
      "6.4\n",
      "6.4\n",
      "6.2\n",
      "6.4\n",
      "6.4\n",
      "6.3\n",
      "6.3\n",
      "6.3\n",
      "6.6\n",
      "6.2\n",
      "6.4\n",
      "6.4\n",
      "6.2\n",
      "6.7\n",
      "6.6\n",
      "6.5\n",
      "6.3\n",
      "6.7\n",
      "6.5\n",
      "6.3\n",
      "6.3\n",
      "6.3\n",
      "6.3\n",
      "6.3\n",
      "6.1\n",
      "6.3\n",
      "6.3\n",
      "6.2\n",
      "6.2\n",
      "6.6\n",
      "6.1\n",
      "6.2\n",
      "6.4\n",
      "6.5\n",
      "6.4\n",
      "6.5\n",
      "6.3\n",
      "6.1\n",
      "6.5\n",
      "6.4\n",
      "6.4\n",
      "6.2\n",
      "6.6\n",
      "6.1\n",
      "6.2\n",
      "6.3\n",
      "6.2\n",
      "6.4\n",
      "6.0\n",
      "6.5\n",
      "6.6\n",
      "6.5\n",
      "6.3\n",
      "6.4\n",
      "6.2\n",
      "6.5\n",
      "6.3\n",
      "6.2\n",
      "6.3\n",
      "6.3\n",
      "6.4\n",
      "6.4\n",
      "6.4\n",
      "6.4\n",
      "6.4\n",
      "6.1\n",
      "6.4\n",
      "6.1\n",
      "6.4\n",
      "6.2\n",
      "6.5\n",
      "6.2\n",
      "6.3\n",
      "6.2\n",
      "6.1\n",
      "6.4\n",
      "6.7\n",
      "6.5\n",
      "6.3\n",
      "6.2\n",
      "6.1\n",
      "6.2\n",
      "6.4\n",
      "6.8\n",
      "6.4\n",
      "6.3\n",
      "6.4\n",
      "6.5\n",
      "6.2\n",
      "6.4\n",
      "6.4\n",
      "6.5\n",
      "6.4\n",
      "6.6\n",
      "6.3\n",
      "6.3\n",
      "6.2\n",
      "6.4\n",
      "6.2\n",
      "6.3\n",
      "6.1\n",
      "6.5\n",
      "6.3\n",
      "6.5\n",
      "6.5\n",
      "6.3\n",
      "6.3\n",
      "6.8\n",
      "6.8\n",
      "6.5\n",
      "6.5\n",
      "6.4\n",
      "6.2\n",
      "6.6\n",
      "6.2\n",
      "6.5\n",
      "6.4\n",
      "6.4\n",
      "6.6\n",
      "6.7\n",
      "6.6\n",
      "6.6\n",
      "6.3\n",
      "6.5\n",
      "6.5\n",
      "6.4\n",
      "6.5\n",
      "6.5\n",
      "6.2\n",
      "6.7\n",
      "6.3\n",
      "6.2\n",
      "6.5\n",
      "6.5\n",
      "6.4\n",
      "6.1\n",
      "6.6\n",
      "6.5\n",
      "6.5\n",
      "6.5\n",
      "6.2\n",
      "6.4\n",
      "6.6\n",
      "6.3\n",
      "6.4\n",
      "6.4\n",
      "6.5\n",
      "6.3\n",
      "6.5\n",
      "6.8\n",
      "6.7\n",
      "6.3\n",
      "6.6\n",
      "6.4\n",
      "6.5\n",
      "6.4\n",
      "6.2\n",
      "6.6\n",
      "6.3\n",
      "6.4\n",
      "6.4\n",
      "6.1\n",
      "6.6\n",
      "6.2\n",
      "6.5\n",
      "6.3\n",
      "6.3\n",
      "6.2\n",
      "6.2\n",
      "6.4\n",
      "6.4\n",
      "6.5\n",
      "6.4\n",
      "6.2\n",
      "6.2\n",
      "6.3\n",
      "6.2\n",
      "6.4\n",
      "6.3\n",
      "6.6\n",
      "6.8\n",
      "6.1\n",
      "6.7\n",
      "6.4\n",
      "6.3\n",
      "6.3\n",
      "6.2\n",
      "6.3\n",
      "6.3\n",
      "6.5\n",
      "-53.9\n",
      "6.0\n",
      "5.8\n",
      "5.9\n",
      "6.4\n",
      "5.9\n",
      "6.1\n",
      "5.7\n",
      "6.2\n",
      "6.4\n",
      "5.7\n",
      "6.4\n",
      "6.0\n",
      "6.1\n",
      "6.2\n",
      "6.2\n",
      "6.1\n",
      "6.1\n",
      "5.9\n",
      "6.2\n",
      "5.8\n",
      "6.1\n",
      "5.8\n",
      "6.0\n",
      "6.0\n",
      "6.3\n",
      "6.0\n",
      "6.1\n",
      "5.9\n",
      "5.9\n",
      "6.3\n",
      "6.3\n",
      "6.0\n",
      "6.1\n",
      "6.1\n",
      "6.0\n",
      "6.3\n",
      "6.1\n",
      "6.4\n",
      "6.2\n",
      "6.2\n",
      "5.9\n",
      "6.0\n",
      "6.0\n",
      "6.5\n",
      "6.3\n",
      "6.3\n",
      "6.1\n",
      "6.2\n",
      "6.3\n",
      "6.2\n",
      "6.2\n",
      "6.2\n",
      "6.1\n",
      "6.1\n",
      "6.2\n",
      "6.2\n",
      "6.2\n",
      "6.1\n",
      "6.4\n",
      "6.0\n",
      "6.4\n",
      "6.2\n",
      "5.9\n",
      "6.1\n",
      "6.0\n",
      "5.9\n",
      "6.2\n",
      "6.4\n",
      "6.3\n",
      "5.8\n",
      "6.0\n",
      "5.9\n",
      "6.1\n",
      "6.1\n",
      "5.9\n",
      "6.1\n",
      "6.0\n",
      "-235.0\n",
      "4.8\n",
      "5.3\n",
      "4.9\n",
      "4.9\n",
      "4.8\n",
      "4.7\n",
      "4.9\n",
      "4.8\n",
      "4.9\n",
      "5.2\n",
      "4.9\n",
      "4.6\n",
      "4.9\n",
      "4.9\n",
      "5.0\n",
      "5.0\n",
      "4.9\n",
      "4.7\n",
      "5.0\n",
      "4.9\n",
      "4.7\n",
      "4.9\n",
      "4.7\n",
      "5.0\n",
      "4.9\n",
      "5.0\n",
      "4.9\n",
      "4.9\n",
      "5.0\n",
      "4.7\n",
      "4.9\n",
      "5.1\n",
      "4.8\n",
      "5.0\n",
      "4.8\n",
      "4.8\n",
      "4.9\n",
      "4.9\n",
      "5.2\n",
      "5.0\n",
      "4.8\n",
      "4.8\n",
      "4.9\n",
      "5.0\n",
      "5.0\n",
      "4.9\n",
      "4.5\n",
      "4.7\n",
      "5.0\n",
      "4.9\n",
      "4.8\n",
      "4.6\n",
      "4.7\n",
      "5.0\n",
      "4.8\n",
      "4.9\n",
      "4.9\n",
      "4.7\n",
      "4.9\n",
      "4.8\n",
      "4.7\n",
      "5.1\n",
      "5.0\n",
      "4.8\n",
      "4.9\n",
      "4.5\n",
      "4.9\n",
      "4.8\n",
      "5.1\n",
      "5.0\n",
      "4.9\n",
      "4.9\n",
      "4.9\n",
      "5.1\n",
      "4.9\n",
      "4.8\n",
      "4.8\n",
      "4.9\n",
      "4.7\n",
      "4.5\n",
      "4.9\n",
      "5.0\n",
      "4.7\n",
      "5.2\n",
      "4.7\n",
      "4.8\n",
      "4.9\n",
      "4.9\n",
      "5.1\n",
      "5.1\n",
      "4.8\n",
      "4.9\n",
      "4.6\n",
      "5.1\n",
      "5.0\n",
      "5.0\n",
      "4.6\n",
      "4.8\n",
      "5.2\n",
      "5.0\n",
      "4.8\n",
      "4.8\n",
      "5.1\n",
      "4.8\n",
      "4.8\n",
      "5.0\n",
      "4.8\n",
      "4.8\n",
      "4.9\n",
      "4.8\n",
      "5.0\n",
      "4.7\n",
      "4.8\n",
      "4.6\n",
      "4.8\n",
      "4.8\n",
      "4.9\n",
      "4.8\n",
      "5.0\n",
      "4.7\n",
      "4.7\n",
      "4.6\n",
      "5.1\n",
      "4.9\n",
      "5.2\n",
      "4.9\n",
      "4.7\n",
      "4.9\n",
      "4.7\n",
      "4.7\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "4.8\n",
      "5.2\n",
      "5.0\n",
      "4.7\n",
      "5.0\n",
      "4.8\n",
      "4.9\n",
      "4.9\n",
      "4.9\n",
      "4.8\n",
      "5.3\n",
      "4.7\n",
      "4.8\n",
      "5.1\n",
      "4.5\n",
      "5.4\n",
      "5.1\n",
      "4.8\n",
      "4.8\n",
      "4.9\n",
      "5.2\n",
      "4.7\n",
      "5.0\n",
      "4.7\n",
      "5.0\n",
      "4.8\n",
      "4.8\n",
      "4.8\n",
      "4.9\n",
      "4.9\n",
      "4.9\n",
      "4.9\n",
      "4.8\n",
      "4.7\n",
      "4.8\n",
      "5.3\n",
      "4.5\n",
      "5.0\n",
      "4.7\n",
      "4.9\n",
      "4.7\n",
      "4.9\n",
      "5.0\n",
      "4.8\n",
      "5.0\n",
      "4.7\n",
      "4.7\n",
      "5.0\n",
      "5.2\n",
      "5.2\n",
      "4.8\n",
      "5.0\n",
      "4.9\n",
      "5.2\n",
      "4.8\n",
      "4.8\n",
      "4.7\n",
      "4.9\n",
      "4.9\n",
      "5.0\n",
      "4.7\n",
      "4.9\n",
      "4.7\n",
      "5.1\n",
      "4.9\n",
      "4.9\n",
      "4.9\n",
      "4.6\n",
      "4.9\n",
      "4.7\n",
      "4.7\n",
      "4.9\n",
      "5.1\n",
      "4.8\n",
      "4.9\n",
      "5.0\n",
      "4.9\n",
      "5.1\n",
      "324.8\n",
      "5.3999999999999995\n",
      "5.0\n",
      "5.1\n",
      "5.1\n",
      "5.199999999999999\n",
      "5.3\n",
      "5.0\n",
      "5.3\n",
      "5.1\n",
      "5.1\n",
      "5.5\n",
      "5.3\n",
      "5.1\n",
      "5.0\n",
      "4.8999999999999995\n",
      "5.1\n",
      "5.0\n",
      "5.3\n",
      "5.3\n",
      "5.0\n",
      "5.1\n",
      "5.3999999999999995\n",
      "5.0\n",
      "5.199999999999999\n",
      "5.199999999999999\n",
      "4.8999999999999995\n",
      "5.5\n",
      "5.3\n",
      "5.3\n",
      "5.0\n",
      "5.199999999999999\n",
      "5.0\n",
      "5.3\n",
      "5.3999999999999995\n",
      "5.3999999999999995\n",
      "5.0\n",
      "5.3999999999999995\n",
      "5.1\n",
      "5.199999999999999\n",
      "5.199999999999999\n",
      "5.199999999999999\n",
      "5.1\n",
      "5.199999999999999\n",
      "5.1\n",
      "5.0\n",
      "5.1\n",
      "5.3999999999999995\n",
      "5.3\n",
      "5.5\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.3\n",
      "6.1\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.5\n",
      "6.3\n",
      "6.7\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.3\n",
      "6.3\n",
      "6.0\n",
      "6.3999999999999995\n",
      "6.6\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.1\n",
      "6.3999999999999995\n",
      "6.3\n",
      "5.8999999999999995\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.3\n",
      "5.8999999999999995\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.3\n",
      "6.3999999999999995\n",
      "5.8999999999999995\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "5.8999999999999995\n",
      "6.3\n",
      "6.0\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.5\n",
      "6.0\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.199999999999999\n",
      "5.8999999999999995\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.0\n",
      "6.0\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.0\n",
      "6.1\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.6\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.5\n",
      "6.1\n",
      "6.3\n",
      "5.8999999999999995\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.0\n",
      "5.8999999999999995\n",
      "6.1\n",
      "6.5\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "5.8999999999999995\n",
      "6.0\n",
      "6.3\n",
      "5.8999999999999995\n",
      "6.3999999999999995\n",
      "6.1\n",
      "5.8999999999999995\n",
      "6.0\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.5\n",
      "6.3\n",
      "6.3\n",
      "6.3999999999999995\n",
      "5.8999999999999995\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.0\n",
      "6.0\n",
      "6.5\n",
      "6.0\n",
      "6.5\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.0\n",
      "5.8999999999999995\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "6.6\n",
      "6.3\n",
      "6.5\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.1\n",
      "6.5\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.5\n",
      "6.199999999999999\n",
      "6.5\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.1\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.0\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.3999999999999995\n",
      "6.5\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.1\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.0\n",
      "6.3\n",
      "6.1\n",
      "6.0\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.199999999999999\n",
      "5.8\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.1\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.1\n",
      "6.7\n",
      "6.5\n",
      "6.3\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.5\n",
      "6.1\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.1\n",
      "6.0\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.6\n",
      "6.5\n",
      "5.8999999999999995\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.1\n",
      "5.8999999999999995\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.5\n",
      "6.3999999999999995\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "5.8999999999999995\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.6\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "6.0\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.0\n",
      "6.5\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.199999999999999\n",
      "6.5\n",
      "6.0\n",
      "6.5\n",
      "6.3\n",
      "5.8999999999999995\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.1\n",
      "6.1\n",
      "6.0\n",
      "6.5\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.1\n",
      "6.1\n",
      "6.6\n",
      "6.1\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.0\n",
      "6.0\n",
      "6.199999999999999\n",
      "5.699999999999999\n",
      "6.3999999999999995\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "5.8999999999999995\n",
      "6.5\n",
      "6.0\n",
      "6.5\n",
      "6.5\n",
      "6.3999999999999995\n",
      "6.1\n",
      "5.8999999999999995\n",
      "6.3999999999999995\n",
      "6.6\n",
      "6.0\n",
      "6.3999999999999995\n",
      "6.5\n",
      "6.3\n",
      "6.3\n",
      "5.8\n",
      "5.8999999999999995\n",
      "5.8999999999999995\n",
      "6.3\n",
      "6.1\n",
      "6.1\n",
      "6.0\n",
      "6.1\n",
      "6.1\n",
      "6.3\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.0\n",
      "6.0\n",
      "6.3\n",
      "6.0\n",
      "5.8999999999999995\n",
      "6.0\n",
      "5.8999999999999995\n",
      "6.1\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.5\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.1\n",
      "6.1\n",
      "6.1\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.3999999999999995\n",
      "5.8999999999999995\n",
      "5.8999999999999995\n",
      "6.3999999999999995\n",
      "6.5\n",
      "6.3\n",
      "6.199999999999999\n",
      "5.699999999999999\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.1\n",
      "6.3\n",
      "6.0\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.0\n",
      "6.0\n",
      "6.7\n",
      "6.199999999999999\n",
      "6.0\n",
      "6.3999999999999995\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.1\n",
      "6.1\n",
      "5.8999999999999995\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.6\n",
      "6.0\n",
      "6.0\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.199999999999999\n",
      "5.8\n",
      "5.8999999999999995\n",
      "6.199999999999999\n",
      "5.8999999999999995\n",
      "6.0\n",
      "6.0\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.0\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.3\n",
      "5.8999999999999995\n",
      "6.6\n",
      "6.3\n",
      "6.1\n",
      "5.699999999999999\n",
      "5.8999999999999995\n",
      "6.1\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "76.7\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.1\n",
      "6.1\n",
      "6.0\n",
      "6.3\n",
      "6.0\n",
      "6.3\n",
      "6.0\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.5\n",
      "6.5\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.3\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.0\n",
      "5.699999999999999\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "6.0\n",
      "6.1\n",
      "6.1\n",
      "6.3\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.3\n",
      "6.1\n",
      "6.3\n",
      "5.8999999999999995\n",
      "6.3\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.3\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "5.8999999999999995\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.0\n",
      "5.8999999999999995\n",
      "6.0\n",
      "6.1\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.5\n",
      "6.1\n",
      "6.5\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.5\n",
      "6.199999999999999\n",
      "6.199999999999999\n",
      "6.6\n",
      "6.6\n",
      "6.3\n",
      "6.3999999999999995\n",
      "6.0\n",
      "6.0\n",
      "6.0\n",
      "6.1\n",
      "6.6\n",
      "6.199999999999999\n",
      "5.8999999999999995\n",
      "6.0\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.3999999999999995\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.1\n",
      "6.1\n",
      "6.5\n",
      "6.5\n",
      "6.3\n",
      "6.0\n",
      "6.0\n",
      "6.3\n",
      "6.0\n",
      "6.3\n",
      "6.6\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.1\n",
      "6.3999999999999995\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "6.3\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.3\n",
      "6.3\n",
      "6.3\n",
      "6.1\n",
      "6.3\n",
      "6.1\n",
      "6.199999999999999\n",
      "6.3\n",
      "6.6\n",
      "6.199999999999999\n",
      "6.3999999999999995\n",
      "-234.79999999999998\n",
      "5.1000000000000005\n",
      "5.0\n",
      "4.800000000000001\n",
      "5.0\n",
      "4.9\n",
      "5.300000000000001\n",
      "5.0\n",
      "5.0\n",
      "4.800000000000001\n",
      "4.9\n",
      "5.0\n",
      "4.9\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.7\n",
      "5.0\n",
      "5.1000000000000005\n",
      "5.4\n",
      "5.0\n",
      "5.300000000000001\n",
      "4.9\n",
      "5.1000000000000005\n",
      "5.1000000000000005\n",
      "5.1000000000000005\n",
      "5.0\n",
      "5.1000000000000005\n",
      "5.1000000000000005\n",
      "4.9\n",
      "5.300000000000001\n",
      "4.9\n",
      "4.7\n",
      "4.9\n",
      "5.0\n",
      "5.1000000000000005\n",
      "4.800000000000001\n",
      "5.0\n",
      "5.2\n",
      "4.800000000000001\n",
      "5.4\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.9\n",
      "5.300000000000001\n",
      "5.1000000000000005\n",
      "5.0\n",
      "5.0\n",
      "5.1000000000000005\n",
      "4.800000000000001\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.800000000000001\n",
      "5.2\n",
      "4.800000000000001\n",
      "4.9\n",
      "4.800000000000001\n",
      "5.2\n",
      "5.2\n",
      "4.800000000000001\n",
      "5.0\n",
      "5.2\n",
      "5.0\n",
      "4.800000000000001\n",
      "5.1000000000000005\n",
      "4.800000000000001\n",
      "4.9\n",
      "5.1000000000000005\n",
      "5.0\n",
      "4.9\n",
      "5.300000000000001\n",
      "5.2\n",
      "5.1000000000000005\n",
      "4.9\n",
      "5.2\n",
      "4.9\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "5.2\n",
      "4.800000000000001\n",
      "4.9\n",
      "5.0\n",
      "5.300000000000001\n",
      "5.4\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "5.0\n",
      "5.4\n",
      "4.9\n",
      "5.1000000000000005\n",
      "5.2\n",
      "5.1000000000000005\n",
      "5.0\n",
      "5.2\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "4.9\n",
      "4.9\n",
      "5.0\n",
      "5.0\n",
      "5.1000000000000005\n",
      "5.0\n",
      "5.0\n",
      "4.800000000000001\n",
      "4.9\n",
      "5.300000000000001\n",
      "5.0\n",
      "5.2\n",
      "5.0\n",
      "5.0\n",
      "5.300000000000001\n",
      "4.9\n",
      "4.9\n",
      "5.1000000000000005\n",
      "4.9\n",
      "5.2\n",
      "4.800000000000001\n",
      "5.1000000000000005\n",
      "5.1000000000000005\n",
      "5.0\n",
      "5.2\n",
      "4.9\n",
      "4.9\n",
      "5.2\n",
      "4.9\n",
      "5.1000000000000005\n",
      "5.0\n",
      "4.7\n",
      "5.2\n",
      "5.300000000000001\n",
      "4.9\n",
      "4.9\n",
      "5.1000000000000005\n",
      "5.1000000000000005\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "5.0\n",
      "5.1000000000000005\n",
      "5.0\n",
      "4.9\n",
      "5.0\n",
      "5.0\n",
      "5.1000000000000005\n",
      "4.7\n",
      "5.0\n",
      "5.2\n",
      "5.0\n",
      "4.9\n",
      "5.2\n",
      "5.0\n",
      "4.7\n",
      "4.7\n",
      "5.0\n",
      "5.1000000000000005\n",
      "5.4\n",
      "5.2\n",
      "4.800000000000001\n",
      "5.0\n",
      "5.300000000000001\n",
      "4.800000000000001\n",
      "5.0\n",
      "4.9\n",
      "4.7\n",
      "5.0\n",
      "5.1000000000000005\n",
      "5.0\n",
      "5.0\n",
      "4.800000000000001\n",
      "5.2\n",
      "4.800000000000001\n",
      "5.2\n",
      "5.1000000000000005\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.9\n",
      "4.800000000000001\n",
      "5.0\n",
      "4.6000000000000005\n",
      "5.0\n",
      "5.1000000000000005\n",
      "4.6000000000000005\n",
      "4.800000000000001\n",
      "4.6000000000000005\n",
      "5.0\n",
      "4.9\n",
      "4.800000000000001\n",
      "5.2\n",
      "5.1000000000000005\n",
      "4.9\n",
      "5.0\n",
      "5.2\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "4.800000000000001\n",
      "5.1000000000000005\n",
      "4.9\n",
      "5.1000000000000005\n",
      "5.0\n",
      "4.7\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.800000000000001\n",
      "5.1000000000000005\n",
      "5.1000000000000005\n",
      "4.7\n",
      "4.800000000000001\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.9\n",
      "5.2\n",
      "4.800000000000001\n",
      "5.0\n",
      "5.300000000000001\n",
      "4.9\n",
      "5.0\n",
      "5.2\n",
      "5.2\n",
      "5.2\n",
      "5.1000000000000005\n",
      "5.1000000000000005\n",
      "4.800000000000001\n",
      "5.1000000000000005\n",
      "5.2\n",
      "5.0\n",
      "4.800000000000001\n",
      "4.9\n",
      "4.9\n",
      "5.2\n",
      "5.1000000000000005\n",
      "4.7\n",
      "4.9\n",
      "5.0\n",
      "5.0\n",
      "5.2\n",
      "4.7\n",
      "4.800000000000001\n",
      "4.7\n",
      "5.1000000000000005\n",
      "5.2\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.9\n",
      "-136.5\n",
      "3.4000000000000004\n",
      "3.3000000000000007\n",
      "3.5000000000000004\n",
      "3.3000000000000007\n",
      "3.3000000000000007\n",
      "3.7000000000000006\n",
      "3.4000000000000004\n",
      "3.6000000000000005\n",
      "3.7000000000000006\n",
      "3.4000000000000004\n",
      "3.5000000000000004\n",
      "3.4000000000000004\n",
      "3.3000000000000007\n",
      "3.4000000000000004\n",
      "3.4000000000000004\n",
      "3.3000000000000007\n",
      "3.6000000000000005\n",
      "3.0000000000000004\n",
      "3.5000000000000004\n",
      "3.4000000000000004\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.7000000000000006\n",
      "3.3000000000000007\n",
      "3.5000000000000004\n",
      "3.3000000000000007\n",
      "3.4000000000000004\n",
      "3.7000000000000006\n",
      "3.5000000000000004\n",
      "3.7000000000000006\n",
      "3.6000000000000005\n",
      "3.4000000000000004\n",
      "3.8000000000000007\n",
      "3.4000000000000004\n",
      "3.2000000000000006\n",
      "3.3000000000000007\n",
      "3.6000000000000005\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.8000000000000007\n",
      "3.4000000000000004\n",
      "3.3000000000000007\n",
      "3.4000000000000004\n",
      "3.7000000000000006\n",
      "3.1000000000000005\n",
      "3.8000000000000007\n",
      "3.4000000000000004\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.7000000000000006\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.4000000000000004\n",
      "3.6000000000000005\n",
      "3.4000000000000004\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.0000000000000004\n",
      "3.8000000000000007\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.2000000000000006\n",
      "3.7000000000000006\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.8000000000000007\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.8000000000000007\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.7000000000000006\n",
      "3.7000000000000006\n",
      "3.3000000000000007\n",
      "3.4000000000000004\n",
      "3.4000000000000004\n",
      "3.4000000000000004\n",
      "3.5000000000000004\n",
      "3.3000000000000007\n",
      "3.7000000000000006\n",
      "3.6000000000000005\n",
      "3.8000000000000007\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.1000000000000005\n",
      "3.8000000000000007\n",
      "3.3000000000000007\n",
      "3.6000000000000005\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.8000000000000007\n",
      "3.7000000000000006\n",
      "3.8000000000000007\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.4000000000000004\n",
      "3.7000000000000006\n",
      "3.8000000000000007\n",
      "3.8000000000000007\n",
      "3.3000000000000007\n",
      "3.4000000000000004\n",
      "3.5000000000000004\n",
      "3.4000000000000004\n",
      "3.6000000000000005\n",
      "3.3000000000000007\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.4000000000000004\n",
      "3.1000000000000005\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.3000000000000007\n",
      "3.6000000000000005\n",
      "3.7000000000000006\n",
      "3.5000000000000004\n",
      "3.3000000000000007\n",
      "3.7000000000000006\n",
      "3.5000000000000004\n",
      "3.2000000000000006\n",
      "3.8000000000000007\n",
      "3.5000000000000004\n",
      "3.3000000000000007\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.5000000000000004\n",
      "3.8000000000000007\n",
      "3.6000000000000005\n",
      "3.7000000000000006\n",
      "3.7000000000000006\n",
      "3.3000000000000007\n",
      "3.5000000000000004\n",
      "3.4000000000000004\n",
      "3.8000000000000007\n",
      "3.7000000000000006\n",
      "3.6000000000000005\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.4000000000000004\n",
      "3.4000000000000004\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.3000000000000007\n",
      "3.3000000000000007\n",
      "3.7000000000000006\n",
      "3.4000000000000004\n",
      "3.4000000000000004\n",
      "3.8000000000000007\n",
      "3.3000000000000007\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.4000000000000004\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.3000000000000007\n",
      "3.5000000000000004\n",
      "3.4000000000000004\n",
      "3.6000000000000005\n",
      "3.3000000000000007\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.7000000000000006\n",
      "3.4000000000000004\n",
      "3.2000000000000006\n",
      "3.5000000000000004\n",
      "3.8000000000000007\n",
      "3.6000000000000005\n",
      "3.5000000000000004\n",
      "3.8000000000000007\n",
      "3.8000000000000007\n",
      "3.5000000000000004\n",
      "3.2000000000000006\n",
      "3.5000000000000004\n",
      "3.4000000000000004\n",
      "3.9000000000000004\n",
      "3.4000000000000004\n",
      "3.4000000000000004\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.3000000000000007\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.3000000000000007\n",
      "3.6000000000000005\n",
      "3.7000000000000006\n",
      "3.4000000000000004\n",
      "3.6000000000000005\n",
      "3.3000000000000007\n",
      "3.6000000000000005\n",
      "3.8000000000000007\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.5000000000000004\n",
      "3.4000000000000004\n",
      "3.3000000000000007\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.7000000000000006\n",
      "3.4000000000000004\n",
      "3.3000000000000007\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.5000000000000004\n",
      "3.7000000000000006\n",
      "3.7000000000000006\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.3000000000000007\n",
      "3.6000000000000005\n",
      "3.4000000000000004\n",
      "3.7000000000000006\n",
      "3.2000000000000006\n",
      "3.5000000000000004\n",
      "3.8000000000000007\n",
      "3.4000000000000004\n",
      "3.6000000000000005\n",
      "3.1000000000000005\n",
      "3.4000000000000004\n",
      "3.3000000000000007\n",
      "3.4000000000000004\n",
      "3.5000000000000004\n",
      "3.5000000000000004\n",
      "3.8000000000000007\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.2000000000000006\n",
      "3.4000000000000004\n",
      "3.2000000000000006\n",
      "3.6000000000000005\n",
      "3.8000000000000007\n",
      "3.8000000000000007\n",
      "3.4000000000000004\n",
      "3.4000000000000004\n",
      "3.8000000000000007\n",
      "3.7000000000000006\n",
      "3.3000000000000007\n",
      "3.7000000000000006\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.6000000000000005\n",
      "3.5000000000000004\n",
      "3.6000000000000005\n",
      "3.8000000000000007\n",
      "3.5000000000000004\n",
      "3.4000000000000004\n",
      "3.7000000000000006\n",
      "3.3000000000000007\n",
      "-247.75\n",
      "2.05\n",
      "2.05\n",
      "2.35\n",
      "2.55\n",
      "2.35\n",
      "2.15\n",
      "2.25\n",
      "2.25\n",
      "2.15\n",
      "2.25\n",
      "2.25\n",
      "2.15\n",
      "2.35\n",
      "2.15\n",
      "2.25\n",
      "2.25\n",
      "2.35\n",
      "2.25\n",
      "2.55\n",
      "2.45\n",
      "2.15\n",
      "2.15\n",
      "2.85\n",
      "2.25\n",
      "2.35\n",
      "2.15\n",
      "2.25\n",
      "2.25\n",
      "1.9500000000000002\n",
      "2.35\n",
      "1.9500000000000002\n",
      "2.35\n",
      "1.9500000000000002\n",
      "2.35\n",
      "2.55\n",
      "2.35\n",
      "2.05\n",
      "2.35\n",
      "2.15\n",
      "2.15\n",
      "2.25\n",
      "2.45\n",
      "2.25\n",
      "2.25\n",
      "2.35\n",
      "1.85\n",
      "2.35\n",
      "2.35\n",
      "2.35\n",
      "2.25\n",
      "2.15\n",
      "2.55\n",
      "1.9500000000000002\n",
      "2.45\n",
      "2.15\n",
      "2.15\n",
      "2.05\n",
      "2.55\n",
      "2.35\n",
      "1.9500000000000002\n",
      "2.35\n",
      "2.45\n",
      "2.35\n",
      "1.85\n",
      "2.45\n",
      "2.55\n",
      "2.45\n",
      "2.15\n",
      "2.45\n",
      "2.45\n",
      "2.15\n",
      "2.25\n",
      "2.15\n",
      "2.25\n",
      "2.05\n",
      "2.25\n",
      "1.85\n",
      "1.9500000000000002\n",
      "2.15\n",
      "2.05\n",
      "2.05\n",
      "2.15\n",
      "2.35\n",
      "2.25\n",
      "2.55\n",
      "2.15\n",
      "2.05\n",
      "2.25\n",
      "2.05\n",
      "1.9500000000000002\n",
      "2.05\n",
      "2.25\n",
      "2.25\n",
      "2.25\n",
      "2.15\n",
      "2.55\n",
      "1.9500000000000002\n",
      "2.15\n",
      "2.15\n",
      "2.05\n",
      "2.45\n",
      "2.25\n",
      "2.25\n",
      "2.25\n",
      "2.25\n",
      "2.05\n",
      "2.45\n",
      "2.25\n",
      "2.15\n",
      "2.45\n",
      "2.55\n",
      "2.15\n",
      "2.45\n",
      "2.25\n",
      "2.25\n",
      "2.55\n",
      "2.15\n",
      "2.15\n",
      "2.15\n",
      "2.65\n",
      "2.25\n",
      "2.25\n",
      "2.25\n",
      "2.55\n",
      "2.25\n",
      "2.05\n",
      "2.15\n",
      "2.35\n",
      "2.15\n",
      "2.25\n",
      "2.15\n",
      "2.75\n",
      "2.55\n",
      "2.35\n",
      "2.45\n",
      "2.05\n",
      "2.25\n",
      "2.35\n",
      "2.15\n",
      "2.35\n",
      "2.45\n",
      "2.45\n",
      "2.45\n",
      "2.15\n",
      "2.35\n",
      "2.65\n",
      "2.05\n",
      "2.35\n",
      "2.55\n",
      "2.25\n",
      "2.55\n",
      "2.05\n",
      "2.25\n",
      "2.35\n",
      "2.45\n",
      "2.35\n",
      "1.9500000000000002\n",
      "2.25\n",
      "2.35\n",
      "1.85\n",
      "2.25\n",
      "2.15\n",
      "2.15\n",
      "2.15\n",
      "2.25\n",
      "2.55\n",
      "2.45\n",
      "2.15\n",
      "2.25\n",
      "2.35\n",
      "2.35\n",
      "2.05\n",
      "2.05\n",
      "2.35\n",
      "2.15\n",
      "2.25\n",
      "2.15\n",
      "1.9500000000000002\n",
      "2.15\n",
      "2.25\n",
      "2.55\n",
      "2.25\n",
      "2.35\n",
      "2.35\n",
      "2.35\n",
      "2.15\n",
      "2.35\n",
      "2.35\n",
      "2.15\n",
      "2.35\n",
      "2.25\n",
      "2.35\n",
      "2.25\n",
      "2.35\n",
      "2.25\n",
      "2.25\n",
      "2.15\n",
      "2.25\n",
      "2.35\n",
      "2.15\n",
      "2.35\n",
      "2.05\n",
      "2.25\n",
      "2.15\n",
      "2.25\n",
      "2.05\n",
      "2.45\n",
      "2.25\n",
      "2.15\n",
      "2.15\n",
      "2.15\n",
      "2.05\n",
      "2.55\n",
      "2.45\n",
      "1.85\n",
      "2.45\n",
      "1.9500000000000002\n",
      "2.35\n",
      "2.25\n",
      "2.35\n",
      "1.9500000000000002\n",
      "2.25\n",
      "1.9500000000000002\n",
      "2.25\n",
      "2.45\n",
      "2.15\n",
      "2.05\n",
      "2.25\n",
      "2.35\n",
      "2.35\n",
      "2.35\n",
      "1.9500000000000002\n",
      "2.55\n",
      "2.25\n",
      "2.35\n",
      "1.9500000000000002\n",
      "2.55\n",
      "2.25\n",
      "2.25\n",
      "2.05\n",
      "1.9500000000000002\n",
      "2.35\n",
      "2.35\n",
      "1.85\n",
      "2.15\n",
      "2.25\n",
      "1.9500000000000002\n",
      "2.25\n",
      "2.55\n",
      "2.15\n",
      "2.25\n",
      "2.15\n",
      "2.25\n",
      "2.15\n",
      "2.15\n",
      "2.05\n",
      "2.55\n",
      "2.25\n",
      "2.05\n",
      "2.25\n",
      "2.35\n",
      "2.25\n",
      "2.35\n",
      "2.25\n",
      "2.55\n",
      "2.15\n",
      "2.15\n",
      "2.15\n",
      "2.15\n",
      "2.25\n",
      "2.15\n",
      "2.35\n",
      "2.35\n",
      "2.15\n",
      "2.15\n",
      "2.35\n",
      "-148.5\n",
      "1.4\n",
      "1.6\n",
      "1.7000000000000002\n",
      "1.6\n",
      "1.5\n",
      "1.9000000000000001\n",
      "1.4\n",
      "1.1\n",
      "1.5\n",
      "1.5\n",
      "1.4\n",
      "1.8\n",
      "1.4\n",
      "1.5\n",
      "1.8\n",
      "1.3\n",
      "1.6\n",
      "1.6\n",
      "1.9000000000000001\n",
      "1.5\n",
      "1.6\n",
      "1.3\n",
      "1.3\n",
      "1.3\n",
      "1.1\n",
      "1.2000000000000002\n",
      "1.5\n",
      "1.6\n",
      "1.3\n",
      "1.5\n",
      "1.7000000000000002\n",
      "1.6\n",
      "1.4\n",
      "1.4\n",
      "1.8\n",
      "1.3\n",
      "1.5\n",
      "1.4\n",
      "1.4\n",
      "1.5\n",
      "1.7000000000000002\n",
      "1.4\n",
      "1.7000000000000002\n",
      "1.3\n",
      "1.5\n",
      "1.2000000000000002\n",
      "1.2000000000000002\n",
      "1.6\n",
      "1.8\n",
      "1.3\n",
      "1.3\n",
      "1.5\n",
      "1.3\n",
      "1.4\n",
      "1.4\n",
      "1.6\n",
      "1.4\n",
      "1.7000000000000002\n",
      "1.5\n",
      "1.6\n",
      "1.4\n",
      "1.4\n",
      "1.7000000000000002\n",
      "1.6\n",
      "1.8\n",
      "1.5\n",
      "1.2000000000000002\n",
      "1.6\n",
      "1.4\n",
      "1.5\n",
      "1.4\n",
      "1.2000000000000002\n",
      "1.4\n",
      "1.4\n",
      "1.7000000000000002\n",
      "1.7000000000000002\n",
      "1.7000000000000002\n",
      "1.4\n",
      "1.8\n",
      "1.6\n",
      "1.5\n",
      "1.4\n",
      "1.3\n",
      "1.4\n",
      "1.5\n",
      "1.8\n",
      "1.4\n",
      "1.6\n",
      "1.3\n",
      "1.7000000000000002\n",
      "1.5\n",
      "1.4\n",
      "1.2000000000000002\n",
      "1.4\n",
      "1.3\n",
      "1.7000000000000002\n",
      "1.7000000000000002\n",
      "1.5\n",
      "1.7000000000000002\n",
      "1.6\n",
      "1.3\n",
      "1.6\n",
      "1.6\n",
      "1.5\n",
      "1.3\n",
      "1.6\n",
      "1.8\n",
      "1.3\n",
      "1.6\n",
      "1.5\n",
      "1.5\n",
      "1.4\n",
      "1.4\n",
      "-48.75\n",
      "-198.75\n",
      "0.9500000000000001\n",
      "1.4500000000000002\n",
      "1.4500000000000002\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.05\n",
      "1.15\n",
      "1.05\n",
      "1.35\n",
      "0.9500000000000001\n",
      "1.55\n",
      "1.25\n",
      "1.35\n",
      "1.05\n",
      "1.35\n",
      "1.4500000000000002\n",
      "1.15\n",
      "1.15\n",
      "1.4500000000000002\n",
      "1.4500000000000002\n",
      "1.05\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.35\n",
      "1.25\n",
      "1.35\n",
      "1.35\n",
      "1.35\n",
      "1.55\n",
      "1.15\n",
      "1.15\n",
      "1.15\n",
      "1.55\n",
      "1.25\n",
      "1.25\n",
      "1.55\n",
      "0.9500000000000001\n",
      "1.15\n",
      "1.25\n",
      "0.8500000000000001\n",
      "1.35\n",
      "0.75\n",
      "1.35\n",
      "1.35\n",
      "1.15\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.25\n",
      "1.05\n",
      "1.25\n",
      "1.05\n",
      "1.35\n",
      "0.9500000000000001\n",
      "1.35\n",
      "1.4500000000000002\n",
      "1.35\n",
      "1.05\n",
      "1.15\n",
      "1.4500000000000002\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.35\n",
      "1.25\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.4500000000000002\n",
      "1.15\n",
      "1.4500000000000002\n",
      "1.6500000000000001\n",
      "1.35\n",
      "1.25\n",
      "1.25\n",
      "1.05\n",
      "1.15\n",
      "1.25\n",
      "0.8500000000000001\n",
      "1.05\n",
      "1.55\n",
      "1.35\n",
      "1.05\n",
      "1.05\n",
      "1.4500000000000002\n",
      "1.15\n",
      "1.15\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.25\n",
      "0.9500000000000001\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.25\n",
      "1.15\n",
      "1.4500000000000002\n",
      "1.35\n",
      "0.9500000000000001\n",
      "1.25\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.4500000000000002\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.05\n",
      "1.25\n",
      "1.55\n",
      "1.15\n",
      "1.35\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.15\n",
      "1.55\n",
      "1.35\n",
      "1.55\n",
      "1.15\n",
      "1.35\n",
      "1.25\n",
      "1.35\n",
      "1.35\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.55\n",
      "1.05\n",
      "1.25\n",
      "1.35\n",
      "0.9500000000000001\n",
      "1.15\n",
      "1.15\n",
      "1.35\n",
      "1.25\n",
      "1.05\n",
      "1.15\n",
      "1.25\n",
      "1.05\n",
      "1.25\n",
      "1.35\n",
      "1.55\n",
      "1.55\n",
      "1.35\n",
      "1.15\n",
      "1.15\n",
      "1.6500000000000001\n",
      "1.15\n",
      "1.15\n",
      "1.05\n",
      "1.05\n",
      "1.05\n",
      "1.55\n",
      "1.4500000000000002\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.25\n",
      "1.15\n",
      "1.15\n",
      "1.35\n",
      "1.55\n",
      "1.35\n",
      "1.15\n",
      "1.35\n",
      "1.15\n",
      "1.4500000000000002\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.4500000000000002\n",
      "1.4500000000000002\n",
      "1.05\n",
      "1.05\n",
      "1.25\n",
      "1.4500000000000002\n",
      "1.4500000000000002\n",
      "1.35\n",
      "1.4500000000000002\n",
      "1.35\n",
      "1.15\n",
      "0.9500000000000001\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.15\n",
      "1.35\n",
      "1.35\n",
      "1.4500000000000002\n",
      "1.35\n",
      "1.25\n",
      "1.25\n",
      "1.15\n",
      "1.05\n",
      "1.15\n",
      "0.9500000000000001\n",
      "1.05\n",
      "1.05\n",
      "1.4500000000000002\n",
      "1.35\n",
      "1.05\n",
      "1.25\n",
      "1.35\n",
      "1.25\n",
      "0.9500000000000001\n",
      "1.05\n",
      "1.55\n",
      "1.15\n",
      "1.25\n",
      "1.35\n",
      "1.15\n",
      "0.8500000000000001\n",
      "1.25\n",
      "1.25\n",
      "1.35\n",
      "1.4500000000000002\n",
      "1.55\n",
      "1.25\n",
      "1.35\n",
      "1.35\n",
      "1.35\n",
      "1.4500000000000002\n",
      "1.05\n",
      "1.35\n",
      "1.05\n",
      "0.9500000000000001\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.15\n",
      "1.05\n",
      "1.05\n",
      "1.25\n",
      "1.55\n",
      "1.4500000000000002\n",
      "1.05\n",
      "1.25\n",
      "1.05\n",
      "1.35\n",
      "1.05\n",
      "1.25\n",
      "1.35\n",
      "1.15\n",
      "1.35\n",
      "1.25\n",
      "1.05\n",
      "1.35\n",
      "0.9500000000000001\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.25\n",
      "1.25\n",
      "1.15\n",
      "1.55\n",
      "1.25\n",
      "1.25\n",
      "1.35\n",
      "1.05\n",
      "1.15\n",
      "1.05\n",
      "1.55\n",
      "1.25\n",
      "1.35\n",
      "1.15\n",
      "1.4500000000000002\n",
      "1.35\n",
      "1.55\n",
      "0.9500000000000001\n",
      "0.9500000000000001\n",
      "1.35\n",
      "1.55\n",
      "1.15\n",
      "1.05\n",
      "1.15\n",
      "1.25\n",
      "1.35\n",
      "1.05\n",
      "1.05\n",
      "1.15\n",
      "1.35\n",
      "1.15\n",
      "0.9500000000000001\n",
      "1.55\n",
      "1.25\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.15\n",
      "1.35\n",
      "1.4500000000000002\n",
      "1.05\n",
      "1.15\n",
      "0.8500000000000001\n",
      "1.25\n",
      "1.15\n",
      "1.25\n",
      "1.4500000000000002\n",
      "1.35\n",
      "1.05\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.05\n",
      "1.15\n",
      "1.15\n",
      "1.05\n",
      "1.25\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.25\n",
      "1.25\n",
      "1.25\n",
      "1.25\n",
      "1.05\n",
      "1.35\n",
      "1.15\n",
      "1.05\n",
      "1.15\n",
      "1.25\n",
      "1.15\n",
      "1.15\n",
      "1.4500000000000002\n",
      "1.15\n",
      "1.25\n",
      "0.9500000000000001\n",
      "1.25\n",
      "1.35\n",
      "1.6500000000000001\n",
      "1.15\n",
      "1.4500000000000002\n",
      "1.55\n",
      "1.4500000000000002\n",
      "1.35\n",
      "1.15\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.15\n",
      "1.35\n",
      "1.15\n",
      "1.25\n",
      "1.25\n",
      "0.9500000000000001\n",
      "1.25\n",
      "0.8500000000000001\n",
      "1.35\n",
      "1.05\n",
      "1.35\n",
      "1.35\n",
      "1.05\n",
      "1.35\n",
      "1.05\n",
      "1.05\n",
      "1.35\n",
      "1.25\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.35\n",
      "1.25\n",
      "1.35\n",
      "1.75\n",
      "1.25\n",
      "1.35\n",
      "1.25\n",
      "1.15\n",
      "1.35\n",
      "1.05\n",
      "1.15\n",
      "1.15\n",
      "0.9500000000000001\n",
      "1.35\n",
      "1.05\n",
      "1.35\n",
      "1.55\n",
      "1.35\n",
      "1.25\n",
      "1.4500000000000002\n",
      "1.35\n",
      "1.15\n",
      "1.25\n",
      "1.25\n",
      "1.05\n",
      "1.35\n",
      "1.35\n",
      "1.25\n",
      "1.15\n",
      "0.9500000000000001\n",
      "1.15\n",
      "1.25\n",
      "1.35\n",
      "1.15\n",
      "1.35\n",
      "1.55\n",
      "1.15\n",
      "1.05\n",
      "1.35\n",
      "1.15\n",
      "1.55\n",
      "1.35\n",
      "1.35\n",
      "1.25\n",
      "1.25\n",
      "1.05\n",
      "1.05\n",
      "1.25\n",
      "1.35\n",
      "0.9500000000000001\n",
      "1.05\n",
      "1.25\n",
      "1.4500000000000002\n",
      "0.8500000000000001\n",
      "1.15\n",
      "1.15\n",
      "1.35\n",
      "1.55\n",
      "1.15\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.25\n",
      "1.25\n",
      "1.15\n",
      "1.55\n",
      "1.4500000000000002\n",
      "1.05\n",
      "1.35\n",
      "1.05\n",
      "1.25\n",
      "1.35\n",
      "1.55\n",
      "1.25\n",
      "1.35\n",
      "1.35\n",
      "1.15\n",
      "1.25\n",
      "1.25\n",
      "1.05\n",
      "1.4500000000000002\n",
      "0.9500000000000001\n",
      "1.05\n",
      "1.4500000000000002\n",
      "1.4500000000000002\n",
      "1.35\n",
      "1.15\n",
      "1.55\n",
      "1.15\n",
      "1.15\n",
      "1.25\n",
      "1.05\n",
      "1.55\n",
      "1.05\n",
      "1.35\n",
      "1.55\n",
      "1.35\n",
      "1.05\n",
      "0.8500000000000001\n",
      "1.55\n",
      "1.25\n",
      "1.15\n",
      "1.05\n",
      "1.05\n",
      "1.35\n",
      "1.25\n",
      "1.4500000000000002\n",
      "1.35\n",
      "1.05\n",
      "1.25\n",
      "1.35\n",
      "1.05\n",
      "1.25\n",
      "1.4500000000000002\n",
      "0.9500000000000001\n",
      "1.35\n",
      "1.25\n",
      "1.6500000000000001\n",
      "1.4500000000000002\n",
      "1.25\n",
      "1.15\n",
      "1.35\n",
      "1.15\n",
      "1.05\n",
      "1.15\n",
      "1.15\n",
      "1.05\n",
      "1.15\n",
      "1.05\n",
      "1.15\n",
      "1.25\n",
      "1.15\n",
      "1.05\n",
      "1.05\n",
      "1.35\n",
      "1.15\n",
      "1.25\n",
      "1.35\n",
      "1.55\n",
      "1.05\n",
      "1.25\n",
      "1.35\n",
      "1.15\n",
      "1.25\n",
      "1.15\n",
      "1.15\n",
      "831.3\n",
      "10.4\n",
      "10.200000000000001\n",
      "10.4\n",
      "10.000000000000002\n",
      "10.3\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.3\n",
      "9.9\n",
      "10.4\n",
      "10.100000000000001\n",
      "10.3\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "10.4\n",
      "10.000000000000002\n",
      "10.4\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "9.8\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.3\n",
      "10.000000000000002\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "9.9\n",
      "9.9\n",
      "10.100000000000001\n",
      "9.9\n",
      "10.000000000000002\n",
      "9.8\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "9.9\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "9.9\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "9.700000000000001\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "9.9\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "10.3\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "9.8\n",
      "10.100000000000001\n",
      "9.9\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "10.600000000000001\n",
      "10.3\n",
      "9.9\n",
      "10.4\n",
      "9.9\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "9.9\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "10.4\n",
      "10.3\n",
      "10.600000000000001\n",
      "10.000000000000002\n",
      "9.8\n",
      "10.100000000000001\n",
      "10.3\n",
      "10.500000000000002\n",
      "10.000000000000002\n",
      "10.3\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "9.9\n",
      "10.200000000000001\n",
      "9.700000000000001\n",
      "10.200000000000001\n",
      "9.700000000000001\n",
      "9.8\n",
      "10.4\n",
      "9.9\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.3\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "9.8\n",
      "9.9\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "10.500000000000002\n",
      "9.9\n",
      "10.3\n",
      "10.3\n",
      "10.000000000000002\n",
      "9.9\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "10.3\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "10.4\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "10.4\n",
      "10.100000000000001\n",
      "10.3\n",
      "9.9\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "10.4\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "9.9\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "10.3\n",
      "9.8\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "10.3\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "9.8\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "9.9\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "9.9\n",
      "9.9\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "9.8\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "9.8\n",
      "10.3\n",
      "10.000000000000002\n",
      "10.3\n",
      "10.000000000000002\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "9.9\n",
      "10.3\n",
      "10.200000000000001\n",
      "10.3\n",
      "10.200000000000001\n",
      "10.4\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "9.8\n",
      "10.3\n",
      "9.8\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "10.4\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "9.8\n",
      "10.200000000000001\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "9.700000000000001\n",
      "10.200000000000001\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.200000000000001\n",
      "10.3\n",
      "9.9\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.100000000000001\n",
      "10.000000000000002\n",
      "10.500000000000002\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.100000000000001\n",
      "10.200000000000001\n",
      "-210.9\n",
      "9.0\n",
      "9.1\n",
      "9.1\n",
      "9.0\n",
      "9.1\n",
      "8.9\n",
      "8.799999999999999\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.299999999999999\n",
      "9.1\n",
      "9.1\n",
      "8.799999999999999\n",
      "9.0\n",
      "8.9\n",
      "9.2\n",
      "8.7\n",
      "9.0\n",
      "9.0\n",
      "9.1\n",
      "9.1\n",
      "9.2\n",
      "8.9\n",
      "9.0\n",
      "9.0\n",
      "9.2\n",
      "9.2\n",
      "9.0\n",
      "9.1\n",
      "8.799999999999999\n",
      "8.799999999999999\n",
      "9.2\n",
      "9.1\n",
      "9.1\n",
      "9.299999999999999\n",
      "9.0\n",
      "9.4\n",
      "9.299999999999999\n",
      "8.799999999999999\n",
      "9.1\n",
      "8.799999999999999\n",
      "8.9\n",
      "9.1\n",
      "8.9\n",
      "9.5\n",
      "9.0\n",
      "8.799999999999999\n",
      "9.299999999999999\n",
      "9.2\n",
      "9.1\n",
      "9.1\n",
      "9.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "9.299999999999999\n",
      "9.0\n",
      "9.299999999999999\n",
      "9.1\n",
      "8.799999999999999\n",
      "9.0\n",
      "8.9\n",
      "9.0\n",
      "9.299999999999999\n",
      "9.0\n",
      "8.9\n",
      "9.1\n",
      "9.2\n",
      "9.299999999999999\n",
      "8.9\n",
      "9.1\n",
      "9.0\n",
      "8.6\n",
      "9.2\n",
      "9.2\n",
      "9.299999999999999\n",
      "9.0\n",
      "9.1\n",
      "9.1\n",
      "8.799999999999999\n",
      "9.1\n",
      "8.5\n",
      "8.6\n",
      "8.9\n",
      "9.0\n",
      "8.7\n",
      "9.1\n",
      "9.0\n",
      "9.1\n",
      "9.1\n",
      "8.6\n",
      "9.0\n",
      "9.2\n",
      "9.2\n",
      "9.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "8.9\n",
      "9.0\n",
      "8.9\n",
      "9.2\n",
      "8.9\n",
      "8.7\n",
      "9.1\n",
      "9.1\n",
      "9.0\n",
      "8.9\n",
      "8.9\n",
      "9.0\n",
      "8.799999999999999\n",
      "9.2\n",
      "9.1\n",
      "9.0\n",
      "9.1\n",
      "9.1\n",
      "8.799999999999999\n",
      "8.799999999999999\n",
      "8.9\n",
      "8.7\n",
      "9.0\n",
      "8.799999999999999\n",
      "9.0\n",
      "8.9\n",
      "8.799999999999999\n",
      "8.9\n",
      "8.9\n",
      "9.0\n",
      "8.799999999999999\n",
      "8.9\n",
      "9.1\n",
      "9.0\n",
      "8.7\n",
      "9.2\n",
      "8.9\n",
      "8.799999999999999\n",
      "9.1\n",
      "9.0\n",
      "8.7\n",
      "9.0\n",
      "8.799999999999999\n",
      "8.9\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "8.6\n",
      "9.299999999999999\n",
      "9.0\n",
      "9.2\n",
      "9.2\n",
      "8.9\n",
      "8.9\n",
      "9.0\n",
      "9.1\n",
      "8.799999999999999\n",
      "8.799999999999999\n",
      "8.9\n",
      "9.1\n",
      "9.299999999999999\n",
      "8.9\n",
      "9.0\n",
      "9.299999999999999\n",
      "8.799999999999999\n",
      "9.2\n",
      "9.2\n",
      "9.2\n",
      "9.0\n",
      "9.1\n",
      "9.299999999999999\n",
      "8.5\n",
      "9.1\n",
      "8.7\n",
      "9.0\n",
      "8.9\n",
      "8.799999999999999\n",
      "9.0\n",
      "9.0\n",
      "9.1\n",
      "9.0\n",
      "9.0\n",
      "9.1\n",
      "8.799999999999999\n",
      "8.799999999999999\n",
      "9.0\n",
      "9.0\n",
      "9.299999999999999\n",
      "8.9\n",
      "9.0\n",
      "8.7\n",
      "9.2\n",
      "8.9\n",
      "9.1\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "9.0\n",
      "8.7\n",
      "9.0\n",
      "9.2\n",
      "9.4\n",
      "9.1\n",
      "8.799999999999999\n",
      "8.9\n",
      "9.4\n",
      "9.4\n",
      "8.9\n",
      "8.9\n",
      "9.0\n",
      "9.0\n",
      "8.9\n",
      "9.0\n",
      "9.1\n",
      "8.9\n",
      "8.9\n",
      "9.2\n",
      "9.1\n",
      "9.0\n",
      "8.9\n",
      "9.0\n",
      "8.9\n",
      "9.299999999999999\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "9.1\n",
      "8.9\n",
      "9.0\n",
      "9.0\n",
      "8.7\n",
      "9.0\n",
      "9.2\n",
      "9.299999999999999\n",
      "9.4\n",
      "9.1\n",
      "8.799999999999999\n",
      "8.799999999999999\n",
      "8.6\n",
      "9.1\n",
      "8.9\n",
      "9.2\n",
      "8.799999999999999\n",
      "9.1\n",
      "8.9\n",
      "-232.1\n",
      "8.0\n",
      "7.800000000000001\n",
      "7.800000000000001\n",
      "7.6000000000000005\n",
      "7.9\n",
      "7.800000000000001\n",
      "8.0\n",
      "7.5\n",
      "7.5\n",
      "8.0\n",
      "7.800000000000001\n",
      "7.7\n",
      "7.6000000000000005\n",
      "7.7\n",
      "7.9\n",
      "7.7\n",
      "7.800000000000001\n",
      "7.800000000000001\n",
      "7.9\n",
      "7.800000000000001\n",
      "7.800000000000001\n",
      "8.1\n",
      "7.800000000000001\n",
      "7.800000000000001\n",
      "7.7\n",
      "7.9\n",
      "7.9\n",
      "7.9\n",
      "7.7\n",
      "7.7\n",
      "7.800000000000001\n",
      "7.6000000000000005\n",
      "7.800000000000001\n",
      "7.800000000000001\n",
      "7.9\n",
      "7.800000000000001\n",
      "8.0\n",
      "7.7\n",
      "8.0\n",
      "7.9\n",
      "7.6000000000000005\n",
      "7.5\n",
      "7.6000000000000005\n",
      "7.7\n",
      "7.5\n",
      "7.7\n",
      "8.0\n",
      "8.0\n",
      "8.0\n",
      "7.9\n",
      "7.7\n",
      "7.9\n",
      "7.5\n",
      "7.9\n",
      "7.7\n",
      "7.800000000000001\n",
      "7.6000000000000005\n",
      "7.6000000000000005\n",
      "7.9\n",
      "7.4\n",
      "7.800000000000001\n",
      "7.6000000000000005\n",
      "7.800000000000001\n",
      "7.7\n",
      "7.5\n",
      "7.800000000000001\n",
      "7.7\n",
      "7.800000000000001\n",
      "7.800000000000001\n",
      "8.0\n",
      "7.800000000000001\n",
      "7.6000000000000005\n",
      "7.800000000000001\n",
      "7.800000000000001\n",
      "7.6000000000000005\n",
      "7.7\n",
      "7.9\n",
      "8.1\n",
      "7.7\n",
      "7.5\n",
      "7.9\n",
      "7.800000000000001\n",
      "7.6000000000000005\n",
      "8.200000000000001\n",
      "7.7\n",
      "7.7\n",
      "8.1\n",
      "7.6000000000000005\n",
      "7.7\n",
      "7.7\n",
      "7.7\n",
      "8.0\n",
      "7.9\n",
      "7.7\n",
      "8.0\n",
      "7.800000000000001\n",
      "7.9\n",
      "7.9\n",
      "8.1\n",
      "7.6000000000000005\n",
      "7.800000000000001\n",
      "7.800000000000001\n",
      "7.800000000000001\n",
      "7.9\n",
      "7.9\n",
      "7.800000000000001\n",
      "7.9\n",
      "7.7\n",
      "7.7\n",
      "7.9\n",
      "7.800000000000001\n",
      "8.0\n",
      "7.800000000000001\n",
      "7.7\n",
      "7.7\n",
      "7.800000000000001\n",
      "8.200000000000001\n",
      "7.6000000000000005\n",
      "7.9\n",
      "8.0\n",
      "7.7\n",
      "7.800000000000001\n",
      "7.800000000000001\n",
      "7.7\n",
      "7.800000000000001\n",
      "7.6000000000000005\n",
      "7.800000000000001\n",
      "7.9\n",
      "7.7\n",
      "7.800000000000001\n",
      "7.7\n",
      "7.9\n",
      "7.800000000000001\n",
      "7.7\n",
      "8.0\n",
      "7.800000000000001\n",
      "7.800000000000001\n",
      "7.7\n",
      "7.9\n",
      "7.7\n",
      "8.0\n",
      "8.0\n",
      "7.800000000000001\n",
      "8.1\n",
      "8.0\n",
      "7.7\n",
      "7.7\n",
      "7.800000000000001\n",
      "7.5\n",
      "7.7\n",
      "8.0\n",
      "7.5\n",
      "7.9\n",
      "7.9\n",
      "7.7\n",
      "7.6000000000000005\n",
      "8.0\n",
      "8.0\n",
      "7.800000000000001\n",
      "7.6000000000000005\n",
      "8.0\n",
      "7.6000000000000005\n",
      "7.9\n",
      "7.9\n",
      "7.7\n",
      "7.6000000000000005\n",
      "7.9\n",
      "7.800000000000001\n",
      "7.7\n",
      "8.1\n",
      "7.7\n",
      "7.800000000000001\n",
      "7.4\n",
      "7.9\n",
      "7.800000000000001\n",
      "7.6000000000000005\n",
      "7.6000000000000005\n",
      "8.0\n",
      "7.800000000000001\n",
      "7.7\n",
      "7.9\n",
      "7.800000000000001\n",
      "7.9\n",
      "8.200000000000001\n",
      "7.5\n",
      "7.800000000000001\n",
      "8.200000000000001\n",
      "7.7\n",
      "7.9\n",
      "-223.45\n",
      "6.550000000000001\n",
      "6.750000000000001\n",
      "7.55\n",
      "7.95\n",
      "7.65\n",
      "7.95\n",
      "7.85\n",
      "7.65\n",
      "7.65\n",
      "7.75\n",
      "7.65\n",
      "7.75\n",
      "7.65\n",
      "7.75\n",
      "7.85\n",
      "7.55\n",
      "7.65\n",
      "7.75\n",
      "7.95\n",
      "7.35\n",
      "7.65\n",
      "7.65\n",
      "7.75\n",
      "7.45\n",
      "7.75\n",
      "7.75\n",
      "7.65\n",
      "7.45\n",
      "7.65\n",
      "7.65\n",
      "7.55\n",
      "7.85\n",
      "7.65\n",
      "7.65\n",
      "8.05\n",
      "7.65\n",
      "7.65\n",
      "7.75\n",
      "7.75\n",
      "7.45\n",
      "7.75\n",
      "7.75\n",
      "7.65\n",
      "7.85\n",
      "7.65\n",
      "7.55\n",
      "7.55\n",
      "7.85\n",
      "7.65\n",
      "7.45\n",
      "7.65\n",
      "7.75\n",
      "7.95\n",
      "7.65\n",
      "7.45\n",
      "7.75\n",
      "7.65\n",
      "7.55\n",
      "7.65\n",
      "7.75\n",
      "7.25\n",
      "7.75\n",
      "8.05\n",
      "7.45\n",
      "7.65\n",
      "7.95\n",
      "7.55\n",
      "7.65\n",
      "7.55\n",
      "7.75\n",
      "7.55\n",
      "7.55\n",
      "7.55\n",
      "7.75\n",
      "7.85\n",
      "7.85\n",
      "7.65\n",
      "7.75\n",
      "7.65\n",
      "7.75\n",
      "7.55\n",
      "7.65\n",
      "7.55\n",
      "7.85\n",
      "7.45\n",
      "7.85\n",
      "7.45\n",
      "7.75\n",
      "7.65\n",
      "7.45\n",
      "7.65\n",
      "7.85\n",
      "7.25\n",
      "7.55\n",
      "7.95\n",
      "7.65\n",
      "7.75\n",
      "7.55\n",
      "7.45\n",
      "7.55\n",
      "7.75\n",
      "7.75\n",
      "7.55\n",
      "7.35\n",
      "7.55\n",
      "7.85\n",
      "7.45\n",
      "7.65\n",
      "7.95\n",
      "7.55\n",
      "7.85\n",
      "7.35\n",
      "7.65\n",
      "7.55\n",
      "7.55\n",
      "7.55\n",
      "7.65\n",
      "7.35\n",
      "7.65\n",
      "7.65\n",
      "7.85\n",
      "7.55\n",
      "7.55\n",
      "7.65\n",
      "7.75\n",
      "7.85\n",
      "7.35\n",
      "7.75\n",
      "7.85\n",
      "7.55\n",
      "7.85\n",
      "7.75\n",
      "7.55\n",
      "7.65\n",
      "7.55\n",
      "7.45\n",
      "7.95\n",
      "7.75\n",
      "7.85\n",
      "7.75\n",
      "7.35\n",
      "7.45\n",
      "7.55\n",
      "7.65\n",
      "7.75\n",
      "7.75\n",
      "7.95\n",
      "7.85\n",
      "7.65\n",
      "7.65\n",
      "7.45\n",
      "7.65\n",
      "7.55\n",
      "7.65\n",
      "7.75\n",
      "7.75\n",
      "7.65\n",
      "7.55\n",
      "7.65\n",
      "7.55\n",
      "7.65\n",
      "7.65\n",
      "7.65\n",
      "7.45\n",
      "7.85\n",
      "7.35\n",
      "7.85\n",
      "7.55\n",
      "7.95\n",
      "7.75\n",
      "7.75\n",
      "7.65\n",
      "7.65\n",
      "7.55\n",
      "7.65\n",
      "7.95\n",
      "7.85\n",
      "7.65\n",
      "7.85\n",
      "7.65\n",
      "7.75\n",
      "7.65\n",
      "7.55\n",
      "7.45\n",
      "7.85\n",
      "7.45\n",
      "7.85\n",
      "7.65\n",
      "7.65\n",
      "7.45\n",
      "7.35\n",
      "7.65\n",
      "7.35\n",
      "7.55\n",
      "7.35\n",
      "7.95\n",
      "7.55\n",
      "7.75\n",
      "7.75\n",
      "7.85\n",
      "7.55\n",
      "7.45\n",
      "7.65\n",
      "7.45\n",
      "7.65\n",
      "7.55\n",
      "7.95\n",
      "7.75\n",
      "7.85\n",
      "7.65\n",
      "7.45\n",
      "7.55\n",
      "7.55\n",
      "7.85\n",
      "7.65\n",
      "7.75\n",
      "7.55\n",
      "7.65\n",
      "7.45\n",
      "7.65\n",
      "8.05\n",
      "7.85\n",
      "7.65\n",
      "7.65\n",
      "7.55\n",
      "7.45\n",
      "7.35\n",
      "7.65\n",
      "7.85\n",
      "7.75\n",
      "7.45\n",
      "7.75\n",
      "7.45\n",
      "7.55\n",
      "7.55\n",
      "7.25\n",
      "7.55\n",
      "7.75\n",
      "7.55\n",
      "7.25\n",
      "7.45\n",
      "7.75\n",
      "7.65\n",
      "7.55\n",
      "7.65\n",
      "7.55\n",
      "-334.25000000000006\n",
      "6.250000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "5.750000000000001\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "5.8500000000000005\n",
      "5.750000000000001\n",
      "6.15\n",
      "6.15\n",
      "6.15\n",
      "5.950000000000001\n",
      "5.65\n",
      "6.250000000000001\n",
      "6.050000000000001\n",
      "5.750000000000001\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "5.8500000000000005\n",
      "6.3500000000000005\n",
      "6.050000000000001\n",
      "6.15\n",
      "6.050000000000001\n",
      "5.750000000000001\n",
      "6.050000000000001\n",
      "5.65\n",
      "5.65\n",
      "6.250000000000001\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "5.65\n",
      "6.3500000000000005\n",
      "5.950000000000001\n",
      "5.65\n",
      "5.8500000000000005\n",
      "5.550000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "6.3500000000000005\n",
      "5.950000000000001\n",
      "6.15\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "6.250000000000001\n",
      "6.050000000000001\n",
      "5.65\n",
      "6.15\n",
      "6.15\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "6.250000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "6.15\n",
      "6.15\n",
      "6.15\n",
      "5.750000000000001\n",
      "5.950000000000001\n",
      "5.750000000000001\n",
      "5.8500000000000005\n",
      "5.750000000000001\n",
      "6.3500000000000005\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "6.15\n",
      "5.8500000000000005\n",
      "6.15\n",
      "6.250000000000001\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "5.8500000000000005\n",
      "5.8500000000000005\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "6.250000000000001\n",
      "5.550000000000001\n",
      "5.8500000000000005\n",
      "6.15\n",
      "5.750000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "6.250000000000001\n",
      "6.050000000000001\n",
      "5.65\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "6.15\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "5.65\n",
      "5.950000000000001\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "5.750000000000001\n",
      "6.050000000000001\n",
      "5.750000000000001\n",
      "5.950000000000001\n",
      "6.15\n",
      "5.950000000000001\n",
      "5.65\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "6.250000000000001\n",
      "5.950000000000001\n",
      "6.250000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "6.15\n",
      "5.750000000000001\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "6.15\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "6.15\n",
      "6.15\n",
      "6.050000000000001\n",
      "5.750000000000001\n",
      "6.050000000000001\n",
      "5.750000000000001\n",
      "6.15\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "5.750000000000001\n",
      "5.950000000000001\n",
      "6.15\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "5.950000000000001\n",
      "6.15\n",
      "5.65\n",
      "5.65\n",
      "5.750000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "6.15\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "6.15\n",
      "5.65\n",
      "6.250000000000001\n",
      "5.950000000000001\n",
      "5.65\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "6.15\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "6.15\n",
      "5.8500000000000005\n",
      "5.8500000000000005\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "5.950000000000001\n",
      "6.250000000000001\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "6.3500000000000005\n",
      "6.050000000000001\n",
      "5.750000000000001\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "6.15\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "5.550000000000001\n",
      "5.950000000000001\n",
      "5.550000000000001\n",
      "5.950000000000001\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "5.750000000000001\n",
      "5.950000000000001\n",
      "5.950000000000001\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "5.65\n",
      "6.250000000000001\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "5.750000000000001\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "6.15\n",
      "5.950000000000001\n",
      "5.65\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "6.15\n",
      "5.550000000000001\n",
      "6.050000000000001\n",
      "6.15\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "6.15\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "5.750000000000001\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "6.15\n",
      "5.8500000000000005\n",
      "6.15\n",
      "5.750000000000001\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "5.65\n",
      "6.050000000000001\n",
      "5.65\n",
      "5.750000000000001\n",
      "6.050000000000001\n",
      "6.250000000000001\n",
      "6.15\n",
      "6.250000000000001\n",
      "5.450000000000001\n",
      "6.050000000000001\n",
      "5.3500000000000005\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "6.15\n",
      "6.15\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "6.050000000000001\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "5.950000000000001\n",
      "5.750000000000001\n",
      "6.250000000000001\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "5.750000000000001\n",
      "6.15\n",
      "5.8500000000000005\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "6.15\n",
      "6.050000000000001\n",
      "5.950000000000001\n",
      "5.8500000000000005\n",
      "5.750000000000001\n",
      "6.15\n",
      "5.550000000000001\n",
      "5.750000000000001\n",
      "5.8500000000000005\n",
      "5.8500000000000005\n",
      "5.65\n",
      "5.8500000000000005\n",
      "6.15\n",
      "5.65\n",
      "6.050000000000001\n",
      "5.8500000000000005\n",
      "6.15\n",
      "6.050000000000001\n",
      "6.250000000000001\n",
      "6.15\n",
      "5.950000000000001\n",
      "6.050000000000001\n",
      "6.250000000000001\n",
      "5.8500000000000005\n",
      "-235.25\n",
      "4.85\n",
      "4.949999999999999\n",
      "4.449999999999999\n",
      "4.949999999999999\n",
      "4.75\n",
      "4.85\n",
      "4.6499999999999995\n",
      "4.85\n",
      "5.05\n",
      "4.55\n",
      "4.449999999999999\n",
      "4.449999999999999\n",
      "4.35\n",
      "4.85\n",
      "4.949999999999999\n",
      "4.75\n",
      "5.25\n",
      "4.85\n",
      "4.85\n",
      "4.75\n",
      "4.75\n",
      "4.85\n",
      "4.949999999999999\n",
      "4.6499999999999995\n",
      "4.6499999999999995\n",
      "4.949999999999999\n",
      "4.55\n",
      "4.75\n",
      "4.85\n",
      "4.949999999999999\n",
      "4.6499999999999995\n",
      "4.55\n",
      "4.85\n",
      "4.55\n",
      "4.449999999999999\n",
      "5.05\n",
      "4.6499999999999995\n",
      "4.949999999999999\n",
      "4.55\n",
      "4.75\n",
      "4.75\n",
      "4.85\n",
      "4.55\n",
      "4.85\n",
      "4.55\n",
      "4.85\n",
      "4.55\n",
      "4.75\n",
      "4.85\n",
      "4.85\n",
      "4.55\n",
      "4.6499999999999995\n",
      "4.55\n",
      "4.85\n",
      "4.85\n",
      "4.6499999999999995\n",
      "4.85\n",
      "4.75\n",
      "4.55\n",
      "4.75\n",
      "4.85\n",
      "4.6499999999999995\n",
      "4.6499999999999995\n",
      "4.6499999999999995\n",
      "4.85\n",
      "4.949999999999999\n",
      "4.6499999999999995\n",
      "4.75\n",
      "4.75\n",
      "4.85\n",
      "4.75\n",
      "4.6499999999999995\n",
      "4.55\n",
      "4.35\n",
      "4.55\n",
      "4.75\n",
      "4.55\n",
      "4.949999999999999\n",
      "4.75\n",
      "4.85\n",
      "4.6499999999999995\n",
      "5.05\n",
      "5.05\n",
      "4.449999999999999\n",
      "4.6499999999999995\n",
      "4.6499999999999995\n",
      "4.85\n",
      "4.6499999999999995\n",
      "4.85\n",
      "4.55\n",
      "4.55\n",
      "4.75\n",
      "4.449999999999999\n",
      "4.6499999999999995\n",
      "4.55\n",
      "4.6499999999999995\n",
      "4.75\n",
      "4.6499999999999995\n",
      "4.55\n",
      "4.85\n",
      "4.85\n",
      "4.75\n",
      "5.25\n",
      "4.6499999999999995\n",
      "4.949999999999999\n",
      "4.6499999999999995\n",
      "4.6499999999999995\n",
      "4.55\n",
      "4.75\n",
      "4.85\n",
      "4.75\n",
      "4.6499999999999995\n",
      "4.949999999999999\n",
      "4.55\n",
      "4.75\n",
      "4.85\n",
      "4.55\n",
      "4.75\n",
      "4.6499999999999995\n",
      "4.75\n",
      "4.6499999999999995\n",
      "4.949999999999999\n",
      "5.05\n",
      "4.85\n",
      "4.75\n",
      "33.549999999999976\n",
      "3.65\n",
      "3.65\n",
      "4.05\n",
      "3.75\n",
      "3.45\n",
      "3.65\n",
      "3.95\n",
      "3.55\n",
      "3.45\n",
      "3.85\n",
      "3.55\n",
      "3.75\n",
      "3.55\n",
      "3.65\n",
      "3.45\n",
      "3.85\n",
      "3.55\n",
      "3.75\n",
      "3.35\n",
      "3.55\n",
      "3.55\n",
      "3.55\n",
      "3.65\n",
      "3.65\n",
      "3.65\n",
      "3.55\n",
      "3.25\n",
      "3.75\n",
      "3.25\n",
      "3.95\n",
      "3.75\n",
      "3.55\n",
      "3.25\n",
      "3.95\n",
      "3.35\n",
      "3.65\n",
      "3.95\n",
      "3.75\n",
      "3.45\n",
      "3.95\n",
      "3.65\n",
      "3.65\n",
      "3.55\n",
      "3.65\n",
      "3.75\n",
      "3.45\n",
      "3.75\n",
      "3.65\n",
      "3.55\n",
      "3.65\n",
      "3.65\n",
      "3.35\n",
      "3.85\n",
      "3.55\n",
      "3.45\n",
      "3.65\n",
      "3.45\n",
      "3.85\n",
      "3.65\n",
      "3.55\n",
      "3.65\n",
      "3.65\n",
      "3.65\n",
      "3.65\n",
      "3.65\n",
      "3.45\n",
      "3.55\n",
      "3.65\n",
      "3.95\n",
      "3.75\n",
      "3.55\n",
      "3.45\n",
      "3.25\n",
      "3.95\n",
      "3.75\n",
      "3.65\n",
      "3.75\n",
      "3.65\n",
      "3.85\n",
      "3.85\n",
      "3.75\n",
      "3.55\n",
      "3.75\n",
      "3.45\n",
      "3.55\n",
      "3.85\n",
      "3.95\n",
      "3.35\n",
      "3.75\n",
      "3.65\n",
      "3.75\n",
      "3.65\n",
      "3.65\n",
      "3.65\n",
      "3.35\n",
      "3.75\n",
      "3.55\n",
      "3.55\n",
      "3.75\n",
      "3.95\n",
      "3.55\n",
      "3.75\n",
      "3.65\n",
      "3.75\n",
      "3.55\n",
      "3.75\n",
      "3.75\n",
      "3.65\n",
      "3.65\n",
      "3.65\n",
      "3.55\n",
      "3.55\n",
      "4.05\n",
      "3.65\n",
      "3.85\n",
      "3.75\n",
      "3.65\n",
      "4.05\n",
      "3.55\n",
      "3.55\n",
      "3.75\n",
      "3.85\n",
      "3.95\n",
      "3.45\n",
      "3.85\n",
      "3.95\n",
      "3.65\n",
      "3.35\n",
      "3.55\n",
      "3.95\n",
      "3.65\n",
      "3.45\n",
      "3.65\n",
      "3.55\n",
      "3.65\n",
      "3.65\n",
      "3.95\n",
      "3.25\n",
      "3.65\n",
      "3.75\n",
      "3.85\n",
      "3.85\n",
      "3.55\n",
      "3.65\n",
      "3.75\n",
      "3.85\n",
      "3.75\n",
      "3.65\n",
      "3.65\n",
      "3.45\n",
      "4.05\n",
      "3.55\n",
      "3.85\n",
      "3.75\n",
      "3.55\n",
      "3.55\n",
      "3.45\n",
      "3.65\n",
      "3.65\n",
      "3.75\n",
      "3.45\n",
      "3.65\n",
      "3.45\n",
      "3.65\n",
      "3.55\n",
      "3.55\n",
      "3.65\n",
      "3.65\n",
      "3.75\n",
      "3.65\n",
      "3.75\n",
      "3.65\n",
      "3.55\n",
      "3.75\n",
      "3.65\n",
      "3.45\n",
      "3.85\n",
      "3.85\n",
      "3.55\n",
      "293.75\n",
      "4.45\n",
      "4.25\n",
      "4.15\n",
      "4.35\n",
      "4.15\n",
      "4.05\n",
      "3.95\n",
      "3.85\n",
      "4.05\n",
      "3.95\n",
      "4.15\n",
      "4.35\n",
      "4.25\n",
      "4.05\n",
      "4.05\n",
      "4.35\n",
      "4.15\n",
      "4.25\n",
      "4.25\n",
      "4.15\n",
      "4.25\n",
      "4.05\n",
      "4.15\n",
      "4.35\n",
      "4.35\n",
      "4.05\n",
      "3.95\n",
      "4.35\n",
      "4.55\n",
      "4.35\n",
      "4.05\n",
      "4.35\n",
      "4.25\n",
      "4.25\n",
      "4.25\n",
      "4.35\n",
      "4.35\n",
      "4.45\n",
      "3.95\n",
      "3.85\n",
      "4.05\n",
      "4.25\n",
      "4.15\n",
      "3.75\n",
      "3.85\n",
      "3.95\n",
      "4.15\n",
      "3.95\n",
      "3.95\n",
      "4.05\n",
      "3.95\n",
      "4.15\n",
      "4.05\n",
      "4.15\n",
      "3.95\n",
      "4.15\n",
      "4.15\n",
      "4.05\n",
      "4.15\n",
      "4.55\n",
      "4.25\n",
      "4.15\n",
      "4.15\n",
      "4.15\n",
      "3.95\n",
      "4.25\n",
      "4.35\n",
      "4.35\n",
      "3.85\n",
      "4.15\n",
      "4.05\n",
      "4.35\n",
      "4.25\n",
      "4.25\n",
      "4.05\n",
      "4.05\n",
      "4.15\n",
      "4.15\n",
      "4.45\n",
      "4.15\n",
      "4.15\n",
      "3.95\n",
      "4.15\n",
      "3.85\n",
      "4.15\n",
      "4.25\n",
      "3.85\n",
      "4.45\n",
      "4.05\n",
      "4.35\n",
      "4.05\n",
      "4.15\n",
      "4.35\n",
      "4.25\n",
      "4.45\n",
      "4.35\n",
      "4.05\n",
      "3.75\n",
      "3.95\n",
      "4.15\n",
      "3.95\n",
      "3.75\n",
      "4.15\n",
      "3.85\n",
      "4.25\n",
      "4.25\n",
      "4.15\n",
      "4.35\n",
      "4.45\n",
      "4.25\n",
      "3.95\n",
      "3.85\n",
      "4.15\n",
      "4.05\n",
      "3.95\n",
      "4.05\n",
      "3.95\n",
      "4.15\n",
      "4.25\n",
      "3.95\n",
      "4.25\n",
      "4.25\n",
      "4.25\n",
      "4.25\n",
      "3.95\n",
      "3.95\n",
      "4.35\n",
      "3.95\n",
      "4.05\n",
      "4.15\n",
      "4.25\n",
      "4.25\n",
      "3.85\n",
      "4.05\n",
      "4.05\n",
      "4.45\n",
      "4.15\n",
      "4.45\n",
      "3.75\n",
      "4.45\n",
      "4.15\n",
      "4.05\n",
      "4.05\n",
      "4.05\n",
      "4.15\n",
      "4.35\n",
      "4.45\n",
      "4.45\n",
      "3.65\n",
      "4.05\n",
      "4.15\n",
      "4.15\n",
      "4.15\n",
      "4.15\n",
      "4.25\n",
      "4.05\n",
      "3.95\n",
      "4.05\n",
      "4.05\n",
      "4.35\n",
      "4.25\n",
      "4.35\n",
      "4.25\n",
      "4.15\n",
      "4.35\n",
      "4.15\n",
      "4.15\n",
      "4.35\n",
      "3.95\n",
      "4.35\n",
      "4.25\n",
      "4.35\n",
      "4.05\n",
      "4.15\n",
      "4.15\n",
      "4.15\n",
      "4.35\n",
      "4.35\n",
      "4.15\n",
      "4.05\n",
      "4.05\n",
      "4.05\n",
      "4.25\n",
      "4.05\n",
      "3.95\n",
      "4.05\n",
      "4.05\n",
      "4.05\n",
      "4.35\n",
      "4.25\n",
      "3.95\n",
      "4.15\n",
      "4.05\n",
      "3.85\n",
      "4.05\n",
      "4.25\n",
      "4.35\n",
      "4.25\n",
      "4.55\n",
      "4.05\n",
      "4.15\n",
      "4.05\n",
      "4.05\n",
      "3.95\n",
      "3.95\n",
      "4.15\n",
      "4.35\n",
      "4.25\n",
      "3.95\n",
      "4.05\n",
      "4.15\n",
      "4.35\n",
      "4.05\n",
      "3.95\n",
      "4.25\n",
      "4.05\n",
      "4.05\n",
      "4.25\n",
      "4.45\n",
      "4.25\n",
      "4.35\n",
      "4.45\n",
      "4.15\n",
      "4.25\n",
      "4.15\n",
      "4.05\n",
      "4.25\n",
      "4.25\n",
      "4.15\n",
      "4.15\n",
      "4.05\n",
      "4.15\n",
      "4.05\n",
      "4.25\n",
      "4.05\n",
      "4.35\n",
      "4.45\n",
      "3.85\n",
      "4.25\n",
      "4.05\n",
      "4.05\n",
      "4.15\n",
      "4.15\n",
      "4.15\n",
      "4.25\n",
      "4.05\n",
      "4.15\n",
      "4.05\n",
      "4.25\n",
      "4.05\n",
      "4.15\n",
      "3.85\n",
      "4.25\n",
      "4.25\n",
      "4.15\n",
      "3.95\n",
      "3.95\n",
      "4.35\n",
      "4.15\n",
      "3.95\n",
      "4.35\n",
      "4.25\n",
      "4.45\n",
      "4.15\n",
      "4.15\n",
      "4.45\n",
      "4.35\n",
      "3.85\n",
      "4.25\n",
      "4.05\n",
      "4.55\n",
      "4.15\n",
      "4.25\n",
      "4.25\n",
      "4.35\n",
      "4.35\n",
      "4.35\n",
      "4.15\n",
      "4.25\n",
      "4.35\n",
      "4.35\n",
      "4.35\n",
      "4.35\n",
      "4.45\n",
      "3.75\n",
      "4.25\n",
      "4.15\n",
      "4.05\n",
      "4.15\n",
      "4.05\n",
      "4.45\n",
      "4.05\n",
      "4.15\n",
      "4.15\n",
      "3.95\n",
      "3.95\n",
      "4.15\n",
      "3.85\n",
      "4.55\n",
      "3.85\n",
      "3.75\n",
      "4.35\n",
      "4.45\n",
      "4.25\n",
      "4.35\n",
      "4.25\n",
      "4.15\n",
      "3.95\n",
      "4.45\n",
      "4.35\n",
      "4.45\n",
      "4.15\n",
      "3.85\n",
      "4.15\n",
      "4.05\n",
      "3.85\n",
      "4.35\n",
      "4.15\n",
      "4.25\n",
      "4.15\n",
      "4.55\n",
      "4.45\n",
      "4.25\n",
      "3.95\n",
      "3.95\n",
      "3.85\n",
      "4.25\n",
      "4.35\n",
      "4.45\n",
      "4.25\n",
      "4.25\n",
      "4.15\n",
      "4.05\n",
      "3.85\n",
      "4.25\n",
      "4.35\n",
      "4.35\n",
      "4.15\n",
      "4.05\n",
      "4.25\n",
      "4.05\n",
      "4.25\n",
      "4.15\n",
      "4.25\n",
      "4.25\n",
      "3.95\n",
      "4.15\n",
      "4.15\n",
      "3.95\n",
      "4.25\n",
      "4.15\n",
      "4.35\n",
      "4.05\n",
      "4.15\n",
      "4.25\n",
      "4.15\n",
      "4.05\n",
      "4.15\n",
      "4.05\n",
      "4.35\n",
      "4.35\n",
      "4.25\n",
      "4.05\n",
      "3.95\n",
      "4.55\n",
      "4.45\n",
      "4.15\n",
      "4.25\n",
      "3.75\n",
      "4.15\n",
      "4.35\n",
      "4.05\n",
      "4.35\n",
      "4.35\n",
      "4.05\n",
      "4.05\n",
      "4.15\n",
      "4.25\n",
      "3.95\n",
      "4.25\n",
      "4.25\n",
      "4.05\n",
      "4.15\n",
      "4.35\n",
      "4.05\n",
      "4.25\n",
      "4.25\n",
      "4.05\n",
      "4.35\n",
      "4.05\n",
      "3.85\n",
      "4.25\n",
      "4.35\n",
      "3.95\n",
      "4.15\n",
      "4.05\n",
      "4.35\n",
      "4.15\n",
      "4.35\n",
      "4.25\n",
      "4.45\n",
      "4.15\n",
      "4.05\n",
      "4.25\n",
      "4.25\n",
      "4.25\n",
      "4.35\n",
      "4.05\n",
      "4.05\n",
      "4.05\n",
      "4.05\n",
      "4.45\n",
      "4.25\n",
      "4.05\n",
      "4.25\n",
      "4.05\n",
      "3.95\n",
      "4.15\n",
      "3.95\n",
      "3.95\n",
      "4.15\n",
      "4.15\n",
      "4.15\n",
      "4.05\n",
      "4.05\n",
      "4.25\n",
      "4.05\n",
      "4.45\n",
      "3.85\n",
      "3.95\n",
      "4.35\n",
      "4.25\n",
      "4.05\n",
      "4.35\n",
      "3.95\n",
      "4.15\n",
      "4.25\n",
      "3.95\n",
      "4.15\n",
      "4.15\n",
      "4.15\n",
      "4.25\n",
      "4.25\n",
      "4.15\n",
      "4.25\n",
      "4.45\n",
      "4.05\n",
      "4.15\n",
      "3.95\n",
      "4.45\n",
      "4.05\n",
      "3.95\n",
      "4.25\n",
      "3.95\n",
      "4.25\n",
      "4.15\n",
      "4.25\n",
      "3.95\n",
      "4.45\n",
      "4.15\n",
      "4.25\n",
      "4.05\n",
      "4.35\n",
      "4.05\n",
      "4.15\n",
      "4.35\n",
      "4.15\n",
      "4.15\n",
      "4.05\n",
      "4.05\n",
      "4.05\n",
      "4.25\n",
      "4.25\n",
      "4.25\n",
      "4.15\n",
      "3.95\n",
      "4.45\n",
      "4.35\n",
      "4.25\n",
      "4.25\n",
      "3.95\n",
      "4.15\n",
      "4.25\n",
      "4.15\n",
      "4.15\n",
      "4.05\n",
      "4.25\n",
      "4.15\n",
      "3.95\n",
      "3.95\n",
      "4.15\n",
      "4.25\n",
      "3.85\n",
      "4.35\n",
      "4.15\n",
      "3.75\n",
      "3.75\n",
      "4.15\n",
      "4.15\n",
      "4.05\n",
      "4.15\n",
      "4.25\n",
      "4.15\n",
      "4.05\n",
      "3.95\n",
      "4.35\n",
      "4.05\n",
      "3.85\n",
      "4.45\n",
      "4.35\n",
      "4.25\n",
      "4.25\n",
      "4.05\n",
      "3.95\n",
      "4.35\n",
      "4.05\n",
      "4.25\n",
      "4.35\n",
      "4.15\n",
      "4.05\n",
      "3.95\n",
      "3.85\n",
      "3.85\n",
      "4.25\n",
      "3.75\n",
      "4.05\n",
      "4.15\n",
      "3.95\n",
      "4.15\n",
      "4.45\n",
      "4.35\n",
      "4.05\n",
      "4.55\n",
      "4.25\n",
      "4.35\n",
      "3.95\n",
      "4.25\n",
      "4.25\n",
      "4.15\n",
      "4.15\n",
      "4.45\n",
      "4.15\n",
      "4.15\n",
      "3.85\n",
      "3.75\n",
      "4.55\n",
      "3.95\n",
      "-116.64999999999999\n",
      "3.5500000000000003\n",
      "3.8500000000000005\n",
      "3.45\n",
      "3.6500000000000004\n",
      "3.5500000000000003\n",
      "3.5500000000000003\n",
      "3.3500000000000005\n",
      "3.5500000000000003\n",
      "3.7500000000000004\n",
      "3.7500000000000004\n",
      "3.95\n",
      "3.5500000000000003\n",
      "3.6500000000000004\n",
      "3.45\n",
      "3.45\n",
      "3.2500000000000004\n",
      "3.3500000000000005\n",
      "3.45\n",
      "3.45\n",
      "3.5500000000000003\n",
      "3.8500000000000005\n",
      "3.7500000000000004\n",
      "3.5500000000000003\n",
      "3.7500000000000004\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.2500000000000004\n",
      "3.45\n",
      "3.3500000000000005\n",
      "3.2500000000000004\n",
      "3.45\n",
      "3.7500000000000004\n",
      "3.5500000000000003\n",
      "3.3500000000000005\n",
      "3.2500000000000004\n",
      "3.3500000000000005\n",
      "3.6500000000000004\n",
      "3.5500000000000003\n",
      "3.3500000000000005\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.5500000000000003\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.5500000000000003\n",
      "3.2500000000000004\n",
      "3.45\n",
      "3.5500000000000003\n",
      "3.5500000000000003\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.5500000000000003\n",
      "3.5500000000000003\n",
      "3.7500000000000004\n",
      "3.1500000000000004\n",
      "3.1500000000000004\n",
      "3.2500000000000004\n",
      "3.5500000000000003\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.5500000000000003\n",
      "3.45\n",
      "3.45\n",
      "3.6500000000000004\n",
      "3.45\n",
      "3.6500000000000004\n",
      "3.5500000000000003\n",
      "3.2500000000000004\n",
      "3.3500000000000005\n",
      "3.3500000000000005\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.45\n",
      "3.2500000000000004\n",
      "3.5500000000000003\n",
      "3.95\n",
      "3.5500000000000003\n",
      "3.6500000000000004\n",
      "3.5500000000000003\n",
      "3.2500000000000004\n",
      "3.7500000000000004\n",
      "3.5500000000000003\n",
      "3.45\n",
      "3.7500000000000004\n",
      "3.7500000000000004\n",
      "3.2500000000000004\n",
      "3.45\n",
      "3.5500000000000003\n",
      "3.45\n",
      "3.5500000000000003\n",
      "3.5500000000000003\n",
      "3.45\n",
      "3.3500000000000005\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.5500000000000003\n",
      "3.3500000000000005\n",
      "3.45\n",
      "3.45\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.3500000000000005\n",
      "3.45\n",
      "3.45\n",
      "3.45\n",
      "3.7500000000000004\n",
      "3.6500000000000004\n",
      "3.45\n",
      "3.6500000000000004\n",
      "3.45\n",
      "3.2500000000000004\n",
      "3.6500000000000004\n",
      "3.45\n",
      "3.3500000000000005\n",
      "3.5500000000000003\n",
      "3.6500000000000004\n",
      "3.2500000000000004\n",
      "3.3500000000000005\n",
      "3.3500000000000005\n",
      "3.5500000000000003\n",
      "3.5500000000000003\n",
      "3.8500000000000005\n",
      "3.45\n",
      "3.7500000000000004\n",
      "3.6500000000000004\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.95\n",
      "3.7500000000000004\n",
      "3.45\n",
      "313.45\n",
      "4.25\n",
      "4.25\n",
      "4.15\n",
      "4.3500000000000005\n",
      "4.15\n",
      "3.95\n",
      "3.95\n",
      "4.050000000000001\n",
      "4.15\n",
      "4.15\n",
      "4.3500000000000005\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.8500000000000005\n",
      "4.15\n",
      "4.15\n",
      "4.050000000000001\n",
      "4.050000000000001\n",
      "3.95\n",
      "4.15\n",
      "3.8500000000000005\n",
      "4.050000000000001\n",
      "3.95\n",
      "4.15\n",
      "4.050000000000001\n",
      "4.25\n",
      "4.3500000000000005\n",
      "3.95\n",
      "4.050000000000001\n",
      "3.95\n",
      "3.8500000000000005\n",
      "3.8500000000000005\n",
      "3.95\n",
      "3.8500000000000005\n",
      "4.15\n",
      "4.15\n",
      "3.95\n",
      "4.15\n",
      "4.15\n",
      "3.8500000000000005\n",
      "4.15\n",
      "4.050000000000001\n",
      "4.050000000000001\n",
      "4.050000000000001\n",
      "3.8500000000000005\n",
      "4.15\n",
      "4.15\n",
      "3.95\n",
      "3.95\n",
      "4.15\n",
      "4.050000000000001\n",
      "3.8500000000000005\n",
      "4.15\n",
      "3.95\n",
      "4.15\n",
      "4.050000000000001\n",
      "4.050000000000001\n",
      "4.15\n",
      "4.15\n",
      "3.8500000000000005\n",
      "4.25\n",
      "4.3500000000000005\n",
      "3.7500000000000004\n",
      "3.95\n",
      "3.95\n",
      "3.8500000000000005\n",
      "4.15\n",
      "3.8500000000000005\n",
      "4.050000000000001\n",
      "4.15\n",
      "3.8500000000000005\n",
      "4.45\n",
      "3.95\n",
      "3.8500000000000005\n",
      "4.050000000000001\n",
      "4.45\n",
      "4.050000000000001\n",
      "4.15\n",
      "4.15\n",
      "3.8500000000000005\n",
      "3.95\n",
      "4.050000000000001\n",
      "4.25\n",
      "4.050000000000001\n",
      "3.95\n",
      "4.25\n",
      "3.7500000000000004\n",
      "3.95\n",
      "4.050000000000001\n",
      "4.15\n",
      "3.95\n",
      "4.15\n",
      "4.15\n",
      "4.050000000000001\n",
      "4.3500000000000005\n",
      "4.15\n",
      "4.050000000000001\n",
      "4.25\n",
      "4.15\n",
      "3.7500000000000004\n",
      "3.95\n",
      "4.15\n",
      "4.050000000000001\n",
      "3.95\n",
      "4.3500000000000005\n",
      "3.8500000000000005\n",
      "4.25\n",
      "3.95\n",
      "3.95\n",
      "4.050000000000001\n",
      "4.15\n",
      "3.95\n",
      "4.25\n",
      "4.3500000000000005\n",
      "4.25\n",
      "4.25\n",
      "4.15\n",
      "4.15\n",
      "3.95\n",
      "3.95\n",
      "3.95\n",
      "3.8500000000000005\n",
      "4.050000000000001\n",
      "3.8500000000000005\n",
      "3.95\n",
      "4.25\n",
      "4.050000000000001\n",
      "4.050000000000001\n",
      "4.050000000000001\n",
      "4.25\n",
      "4.25\n",
      "4.15\n",
      "3.7500000000000004\n",
      "4.15\n",
      "3.95\n",
      "4.15\n",
      "4.25\n",
      "3.5500000000000003\n",
      "3.7500000000000004\n",
      "4.3500000000000005\n",
      "4.3500000000000005\n",
      "3.95\n",
      "4.15\n",
      "4.3500000000000005\n",
      "4.15\n",
      "4.050000000000001\n",
      "4.25\n",
      "4.15\n",
      "4.15\n",
      "4.050000000000001\n",
      "4.25\n",
      "3.95\n",
      "4.15\n",
      "4.050000000000001\n",
      "-56.35\n",
      "-196.55\n",
      "3.8500000000000005\n",
      "3.5500000000000007\n",
      "3.7500000000000004\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "3.7500000000000004\n",
      "3.5500000000000007\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.7500000000000004\n",
      "3.4500000000000006\n",
      "3.3500000000000005\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.9500000000000006\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.8500000000000005\n",
      "3.5500000000000007\n",
      "3.9500000000000006\n",
      "3.7500000000000004\n",
      "3.6500000000000004\n",
      "3.4500000000000006\n",
      "4.15\n",
      "3.6500000000000004\n",
      "4.050000000000001\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.9500000000000006\n",
      "3.4500000000000006\n",
      "3.7500000000000004\n",
      "3.9500000000000006\n",
      "3.5500000000000007\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.7500000000000004\n",
      "4.15\n",
      "3.7500000000000004\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.5500000000000007\n",
      "3.5500000000000007\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.7500000000000004\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.4500000000000006\n",
      "3.8500000000000005\n",
      "3.4500000000000006\n",
      "3.5500000000000007\n",
      "4.050000000000001\n",
      "4.050000000000001\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "3.5500000000000007\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.7500000000000004\n",
      "3.9500000000000006\n",
      "3.3500000000000005\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.7500000000000004\n",
      "3.5500000000000007\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.7500000000000004\n",
      "3.6500000000000004\n",
      "3.5500000000000007\n",
      "3.9500000000000006\n",
      "3.3500000000000005\n",
      "3.8500000000000005\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "4.050000000000001\n",
      "3.6500000000000004\n",
      "3.3500000000000005\n",
      "3.7500000000000004\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "3.7500000000000004\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.8500000000000005\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "3.5500000000000007\n",
      "3.4500000000000006\n",
      "4.050000000000001\n",
      "4.050000000000001\n",
      "3.9500000000000006\n",
      "3.8500000000000005\n",
      "3.9500000000000006\n",
      "3.8500000000000005\n",
      "4.050000000000001\n",
      "3.9500000000000006\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "3.5500000000000007\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "4.050000000000001\n",
      "3.9500000000000006\n",
      "4.050000000000001\n",
      "3.8500000000000005\n",
      "4.050000000000001\n",
      "3.9500000000000006\n",
      "3.8500000000000005\n",
      "3.7500000000000004\n",
      "3.9500000000000006\n",
      "3.7500000000000004\n",
      "3.5500000000000007\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "3.6500000000000004\n",
      "4.050000000000001\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.5500000000000007\n",
      "3.8500000000000005\n",
      "3.5500000000000007\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "3.8500000000000005\n",
      "3.7500000000000004\n",
      "3.7500000000000004\n",
      "3.7500000000000004\n",
      "3.7500000000000004\n",
      "3.8500000000000005\n",
      "3.3500000000000005\n",
      "3.4500000000000006\n",
      "3.8500000000000005\n",
      "3.5500000000000007\n",
      "3.6500000000000004\n",
      "4.15\n",
      "3.8500000000000005\n",
      "3.9500000000000006\n",
      "3.8500000000000005\n",
      "3.9500000000000006\n",
      "3.6500000000000004\n",
      "3.5500000000000007\n",
      "3.5500000000000007\n",
      "3.6500000000000004\n",
      "3.8500000000000005\n",
      "3.8500000000000005\n",
      "3.8500000000000005\n",
      "3.9500000000000006\n",
      "3.7500000000000004\n",
      "3.6500000000000004\n",
      "4.050000000000001\n",
      "4.050000000000001\n",
      "3.5500000000000007\n",
      "3.5500000000000007\n",
      "3.6500000000000004\n",
      "3.6500000000000004\n",
      "3.7500000000000004\n",
      "3.9500000000000006\n",
      "3.8500000000000005\n",
      "3.8500000000000005\n",
      "3.6500000000000004\n",
      "3.9500000000000006\n",
      "3.8500000000000005\n",
      "3.7500000000000004\n",
      "3.9500000000000006\n",
      "3.5500000000000007\n",
      "4.65\n",
      "4.8500000000000005\n",
      "4.550000000000001\n",
      "4.550000000000001\n",
      "4.550000000000001\n",
      "4.75\n",
      "4.65\n",
      "5.050000000000001\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.65\n",
      "4.65\n",
      "4.95\n",
      "4.8500000000000005\n",
      "4.75\n",
      "4.75\n",
      "4.45\n",
      "4.550000000000001\n",
      "4.65\n",
      "4.65\n",
      "4.65\n",
      "4.550000000000001\n",
      "4.550000000000001\n",
      "4.95\n",
      "4.8500000000000005\n",
      "4.8500000000000005\n",
      "4.550000000000001\n",
      "4.45\n",
      "4.65\n",
      "4.95\n",
      "4.8500000000000005\n",
      "4.65\n",
      "4.65\n",
      "4.65\n",
      "4.75\n",
      "4.95\n",
      "4.75\n",
      "4.65\n",
      "4.8500000000000005\n",
      "5.050000000000001\n",
      "4.75\n",
      "4.65\n",
      "4.65\n",
      "4.65\n",
      "4.95\n",
      "4.65\n",
      "5.050000000000001\n",
      "4.45\n",
      "4.65\n",
      "4.550000000000001\n",
      "4.75\n",
      "4.75\n",
      "4.65\n",
      "5.050000000000001\n",
      "4.75\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.65\n",
      "4.65\n",
      "5.050000000000001\n",
      "4.65\n",
      "4.550000000000001\n",
      "4.65\n",
      "4.95\n",
      "4.550000000000001\n",
      "4.75\n",
      "4.65\n",
      "4.8500000000000005\n",
      "4.8500000000000005\n",
      "4.65\n",
      "4.75\n",
      "4.95\n",
      "4.550000000000001\n",
      "4.8500000000000005\n",
      "4.8500000000000005\n",
      "4.8500000000000005\n",
      "5.050000000000001\n",
      "4.8500000000000005\n",
      "4.95\n",
      "4.75\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.95\n",
      "4.75\n",
      "5.050000000000001\n",
      "4.75\n",
      "4.65\n",
      "4.95\n",
      "4.3500000000000005\n",
      "4.8500000000000005\n",
      "4.8500000000000005\n",
      "4.550000000000001\n",
      "4.95\n",
      "4.65\n",
      "5.250000000000001\n",
      "4.75\n",
      "4.65\n",
      "4.95\n",
      "4.8500000000000005\n",
      "4.65\n",
      "4.550000000000001\n",
      "4.550000000000001\n",
      "5.050000000000001\n",
      "4.75\n",
      "5.050000000000001\n",
      "4.75\n",
      "5.050000000000001\n",
      "4.75\n",
      "4.75\n",
      "4.550000000000001\n",
      "4.95\n",
      "4.65\n",
      "5.15\n",
      "5.050000000000001\n",
      "4.65\n",
      "4.45\n",
      "4.3500000000000005\n",
      "4.45\n",
      "4.95\n",
      "4.75\n",
      "4.550000000000001\n",
      "4.8500000000000005\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.65\n",
      "4.75\n",
      "4.45\n",
      "4.65\n",
      "4.75\n",
      "5.050000000000001\n",
      "5.050000000000001\n",
      "4.550000000000001\n",
      "4.75\n",
      "4.75\n",
      "4.95\n",
      "4.45\n",
      "4.8500000000000005\n",
      "4.45\n",
      "4.75\n",
      "4.75\n",
      "4.95\n",
      "4.75\n",
      "4.65\n",
      "4.95\n",
      "4.45\n",
      "4.8500000000000005\n",
      "4.75\n",
      "4.95\n",
      "4.65\n",
      "4.8500000000000005\n",
      "4.550000000000001\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.65\n",
      "4.75\n",
      "4.65\n",
      "4.95\n",
      "4.75\n",
      "4.75\n",
      "4.8500000000000005\n",
      "5.050000000000001\n",
      "5.15\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.75\n",
      "4.95\n",
      "4.65\n",
      "4.65\n",
      "4.550000000000001\n",
      "4.550000000000001\n",
      "4.65\n",
      "5.15\n",
      "4.75\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.75\n",
      "4.75\n",
      "4.75\n",
      "4.75\n",
      "4.95\n",
      "4.75\n",
      "4.95\n",
      "4.8500000000000005\n",
      "4.8500000000000005\n",
      "4.8500000000000005\n",
      "4.65\n",
      "5.050000000000001\n",
      "4.65\n",
      "5.050000000000001\n",
      "4.75\n",
      "4.75\n",
      "4.75\n",
      "4.65\n",
      "4.550000000000001\n",
      "4.65\n",
      "4.95\n",
      "4.550000000000001\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.95\n",
      "4.8500000000000005\n",
      "4.550000000000001\n",
      "4.65\n",
      "5.15\n",
      "4.65\n",
      "5.050000000000001\n",
      "4.550000000000001\n",
      "4.75\n",
      "4.3500000000000005\n",
      "4.550000000000001\n",
      "4.8500000000000005\n",
      "5.050000000000001\n",
      "4.8500000000000005\n",
      "4.8500000000000005\n",
      "4.65\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.75\n",
      "4.65\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.75\n",
      "4.95\n",
      "4.75\n",
      "4.75\n",
      "4.45\n",
      "4.75\n",
      "4.75\n",
      "5.050000000000001\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.8500000000000005\n",
      "4.75\n",
      "4.95\n",
      "5.15\n",
      "4.8500000000000005\n",
      "4.65\n",
      "4.65\n",
      "5.050000000000001\n",
      "4.8500000000000005\n",
      "4.8500000000000005\n",
      "4.550000000000001\n",
      "4.75\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.8500000000000005\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.75\n",
      "4.550000000000001\n",
      "4.550000000000001\n",
      "4.65\n",
      "4.65\n",
      "4.8500000000000005\n",
      "4.550000000000001\n",
      "4.75\n",
      "4.3500000000000005\n",
      "4.8500000000000005\n",
      "4.65\n",
      "5.050000000000001\n",
      "4.65\n",
      "4.95\n",
      "4.65\n",
      "4.550000000000001\n",
      "5.050000000000001\n",
      "4.95\n",
      "4.550000000000001\n",
      "4.65\n",
      "4.65\n",
      "4.65\n",
      "4.550000000000001\n",
      "5.15\n",
      "4.65\n",
      "4.65\n",
      "4.75\n",
      "4.75\n",
      "4.8500000000000005\n",
      "4.95\n",
      "4.65\n",
      "5.15\n",
      "4.65\n",
      "4.95\n",
      "815.0\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.6000000000000005\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "4.7\n",
      "4.6000000000000005\n",
      "4.800000000000001\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.7\n",
      "4.7\n",
      "4.6000000000000005\n",
      "5.0\n",
      "4.9\n",
      "4.5\n",
      "5.0\n",
      "4.5\n",
      "4.7\n",
      "4.7\n",
      "5.0\n",
      "4.7\n",
      "5.2\n",
      "4.7\n",
      "5.0\n",
      "4.5\n",
      "4.9\n",
      "4.800000000000001\n",
      "5.0\n",
      "5.0\n",
      "4.5\n",
      "4.800000000000001\n",
      "5.0\n",
      "4.9\n",
      "4.6000000000000005\n",
      "4.800000000000001\n",
      "4.6000000000000005\n",
      "4.7\n",
      "4.9\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.7\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "5.0\n",
      "4.7\n",
      "4.6000000000000005\n",
      "5.0\n",
      "4.6000000000000005\n",
      "4.800000000000001\n",
      "4.9\n",
      "4.9\n",
      "4.9\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.4\n",
      "4.7\n",
      "4.9\n",
      "5.0\n",
      "4.9\n",
      "5.0\n",
      "4.9\n",
      "5.1000000000000005\n",
      "4.7\n",
      "5.0\n",
      "4.800000000000001\n",
      "4.7\n",
      "4.7\n",
      "4.800000000000001\n",
      "4.7\n",
      "4.800000000000001\n",
      "4.7\n",
      "4.800000000000001\n",
      "4.9\n",
      "4.7\n",
      "4.7\n",
      "4.7\n",
      "4.800000000000001\n",
      "4.4\n",
      "4.6000000000000005\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.5\n",
      "4.9\n",
      "4.7\n",
      "5.0\n",
      "5.1000000000000005\n",
      "4.7\n",
      "4.9\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.6000000000000005\n",
      "4.7\n",
      "4.7\n",
      "4.7\n",
      "4.800000000000001\n",
      "4.5\n",
      "4.9\n",
      "4.7\n",
      "4.7\n",
      "4.9\n",
      "4.4\n",
      "4.7\n",
      "5.0\n",
      "4.7\n",
      "5.0\n",
      "4.6000000000000005\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "4.6000000000000005\n",
      "4.7\n",
      "5.0\n",
      "4.800000000000001\n",
      "4.6000000000000005\n",
      "4.9\n",
      "5.0\n",
      "4.7\n",
      "4.5\n",
      "5.1000000000000005\n",
      "4.800000000000001\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.5\n",
      "4.9\n",
      "4.7\n",
      "5.2\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.9\n",
      "5.1000000000000005\n",
      "4.7\n",
      "4.7\n",
      "4.9\n",
      "4.6000000000000005\n",
      "4.5\n",
      "5.1000000000000005\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.9\n",
      "4.6000000000000005\n",
      "4.7\n",
      "4.800000000000001\n",
      "4.6000000000000005\n",
      "4.7\n",
      "5.2\n",
      "4.9\n",
      "5.1000000000000005\n",
      "4.9\n",
      "5.1000000000000005\n",
      "4.7\n",
      "4.7\n",
      "4.9\n",
      "4.9\n",
      "4.800000000000001\n",
      "4.800000000000001\n",
      "4.9\n",
      "5.0\n",
      "4.9\n",
      "4.9\n",
      "4.7\n",
      "5.0\n",
      "4.6000000000000005\n",
      "4.4\n",
      "5.0\n",
      "4.800000000000001\n",
      "4.8\n"
     ]
    }
   ],
   "source": [
    "# Reset game to starting state\n",
    "obs = env.reset()\n",
    "# Set flag to flase\n",
    "done = False\n",
    "for game in range(1): \n",
    "    while not done: \n",
    "        if done: \n",
    "            obs = env.reset()\n",
    "        env.render()\n",
    "        obs, reward, done, info = env.step(env.action_space.sample())\n",
    "        time.sleep(0.01)\n",
    "        if reward != 0:\n",
    "            print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closes the game environment - important given we can only run one at a time \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd7516a4b80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cv2.cvtColor(obs, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is what we are feeding into model^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/get-started/locally/  <- use this site to download pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.8/site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.8/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.8/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.8/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3\n",
      "  Obtaining dependency information for stable-baselines3 from https://files.pythonhosted.org/packages/06/6a/c3098a78a63b5a48e18c11d80b8c532f8b7785d6abb1329cfe3034572161/stable_baselines3-2.3.2-py3-none-any.whl.metadata\n",
      "  Using cached stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting gymnasium<0.30,>=0.28.1 (from stable-baselines3)\n",
      "  Obtaining dependency information for gymnasium<0.30,>=0.28.1 from https://files.pythonhosted.org/packages/a8/4d/3cbfd81ed84db450dbe73a89afcd8bc405273918415649ac6683356afe92/gymnasium-0.29.1-py3-none-any.whl.metadata\n",
      "  Using cached gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in ./.venv/lib/python3.8/site-packages (from stable-baselines3) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.13 in ./.venv/lib/python3.8/site-packages (from stable-baselines3) (2.2.2)\n",
      "Requirement already satisfied: cloudpickle in ./.venv/lib/python3.8/site-packages (from stable-baselines3) (3.1.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.8/site-packages (from stable-baselines3) (2.0.3)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.8/site-packages (from stable-baselines3) (3.7.5)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./.venv/lib/python3.8/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.2)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3)\n",
      "  Obtaining dependency information for farama-notifications>=0.0.1 from https://files.pythonhosted.org/packages/05/2c/ffc08c54c05cdce6fbed2aeebc46348dbe180c6d2c541c7af7ba0aa5f5f8/Farama_Notifications-0.0.4-py3-none-any.whl.metadata\n",
      "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in ./.venv/lib/python3.8/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (8.5.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3) (3.16.1)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3) (2024.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas->stable-baselines3) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.8/site-packages (from pandas->stable-baselines3) (2024.2)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gymnasium<0.30,>=0.28.1->stable-baselines3) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.8/site-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.8/site-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
      "Using cached stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
      "Using cached gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium, stable-baselines3\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 stable-baselines3-2.3.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyglet==1.3.2\n",
      "  Obtaining dependency information for pyglet==1.3.2 from https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading pyglet-1.3.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting future (from pyglet==1.3.2)\n",
      "  Obtaining dependency information for future from https://files.pythonhosted.org/packages/da/71/ae30dadffc90b9006d77af76b393cb9dfbfc9629f339fc1574a1c52e6806/future-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Downloading pyglet-1.3.2-py2.py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.0 MB 2.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.2/1.0 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.4/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.5/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.6/1.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 0.9/1.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "   ---------------------------------------- 0.0/491.3 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 102.4/491.3 kB 2.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 256.0/491.3 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 419.8/491.3 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 491.3/491.3 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: future, pyglet\n",
      "  Attempting uninstall: pyglet\n",
      "    Found existing installation: pyglet 1.5.29\n",
      "    Uninstalling pyglet-1.5.29:\n",
      "      Successfully uninstalled pyglet-1.5.29\n",
      "Successfully installed future-1.0.0 pyglet-1.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install pyglet==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in ./.venv/lib/python3.8/site-packages (4.0.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./.venv/lib/python3.8/site-packages (from optuna) (1.13.3)\n",
      "Requirement already satisfied: colorlog in ./.venv/lib/python3.8/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (from optuna) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./.venv/lib/python3.8/site-packages (from optuna) (2.0.36)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.8/site-packages (from optuna) (4.66.6)\n",
      "Requirement already satisfied: PyYAML in ./.venv/lib/python3.8/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in ./.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in ./.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: importlib-metadata in ./.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (8.5.0)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (6.4.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.8/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./.venv/lib/python3.8/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the optimzation frame - HPO\n",
    "import optuna\n",
    "# PPO algo for RL\n",
    "from stable_baselines3 import PPO\n",
    "# Bring in the eval policy method for metric calculation\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "# Import the sb3 monitor for logging \n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "# Import the vec wrappers to vectorize and frame stack\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "# Import os to deal with filepaths\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './logs/'\n",
    "OPT_DIR = './opt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return test hyperparameters - define the object function\n",
    "def optimize_ppo(trial): \n",
    "    return {\n",
    "        'n_steps':trial.suggest_int('n_steps', 2048, 8192), # number of frames used in one batch of training (must use a factor of 64) (maybe take a number and multiply it by 64? )\n",
    "        'gamma':trial.suggest_loguniform('gamma', 0.8, 0.9999), # discount rate\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate', 1e-5, 1e-4), # how fast we tune optimizer (Critic and Actor for PPO)\n",
    "        'clip_range':trial.suggest_uniform('clip_range', 0.1, 0.4), # how far we want to clip for our advantage value in PPO\n",
    "        'gae_lambda':trial.suggest_uniform('gae_lambda', 0.8, 0.99) # smoothing parameter (used when calculating advantage)\n",
    "    }\n",
    "\n",
    "# IF U WANT TO USE OTHER ALGOS THE HYPERPARAMS MUST BE SWITCHED AS WELL (DQN, SAC, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative version to use later to bypass factor 64 error\n",
    "\n",
    "\n",
    "\n",
    "# # PPO optimization parameters\n",
    "\n",
    "# PPO_PARAMS = {\n",
    "\n",
    "#     'n_steps_range': (2048, 8192),\n",
    "\n",
    "#     'gamma_range': (0.8, 0.9999),\n",
    "\n",
    "#     'learning_rate_range': (1e-5, 1e-4),\n",
    "\n",
    "#     'clip_range_range': (0.1, 0.4),\n",
    "\n",
    "#     'gae_lambda_range': (0.8, 0.99),\n",
    "\n",
    "# }\n",
    "\n",
    "# # Define the optimization function for PPO\n",
    "\n",
    "# def optimize_ppo(trial): \n",
    "\n",
    "#     n_steps = trial.suggest_categorical('n_steps', range(PPO_PARAMS['n_steps_range'][0], PPO_PARAMS['n_steps_range'][1], 64))  # Steps of 64\n",
    "\n",
    "#     return {\n",
    "\n",
    "#         'n_steps': n_steps,\n",
    "\n",
    "#         'gamma': trial.suggest_loguniform('gamma', *PPO_PARAMS['gamma_range']),\n",
    "\n",
    "#         'learning_rate': trial.suggest_loguniform('learning_rate', *PPO_PARAMS['learning_rate_range']),\n",
    "\n",
    "#         'clip_range': trial.suggest_uniform('clip_range', *PPO_PARAMS['clip_range_range']),\n",
    "\n",
    "#         'gae_lambda': trial.suggest_uniform('gae_lambda', *PPO_PARAMS['gae_lambda_range']),\n",
    "\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = os.path.join(OPT_DIR, 'trial_{}_best_model'.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a training loop and return mean reward \n",
    "def optimize_agent(trial):\n",
    "    # try:\n",
    "        model_params = optimize_ppo(trial)  # get dict of hyperparams\n",
    "\n",
    "        # Create environment \n",
    "        env = StreetFighter()\n",
    "        env = Monitor(env, LOG_DIR) # allowd for logging mean episode reward and mean episode length\n",
    "        env = DummyVecEnv([lambda: env])\n",
    "        env = VecFrameStack(env, 4, channels_order='last')\n",
    "\n",
    "        # Create algo \n",
    "        model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=0, **model_params) # uses model params dict\n",
    "        model.learn(total_timesteps=10000) # 100000 for production model (longer if can)\n",
    "\n",
    "        # Evaluate model \n",
    "        mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=1) # 5 different games usually but went lower cuz i dont got cuda (those who know)\n",
    "        env.close()\n",
    "\n",
    "        SAVE_PATH = os.path.join(OPT_DIR, 'trial_{}_best_model'.format(trial.number))\n",
    "        model.save(SAVE_PATH)\n",
    "\n",
    "        return mean_reward\n",
    "\n",
    "    # except Exception as e: # used in case hyperparam throws error (allows to continue training)\n",
    "    #     return -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:21:22,524] A new study created in memory with name: no-name-75b592f5-3a58-44ac-9aec-20831c7c628e\n",
      "/var/folders/d4/_v_lx6gx66z8htqrwxr89lvc0000gn/T/ipykernel_86005/3706438210.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'gamma':trial.suggest_loguniform('gamma', 0.8, 0.9999), # discount rate\n",
      "/var/folders/d4/_v_lx6gx66z8htqrwxr89lvc0000gn/T/ipykernel_86005/3706438210.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate', 1e-5, 1e-4), # how fast we tune optimizer (Critic and Actor for PPO)\n",
      "/var/folders/d4/_v_lx6gx66z8htqrwxr89lvc0000gn/T/ipykernel_86005/3706438210.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'clip_range':trial.suggest_uniform('clip_range', 0.1, 0.4), # how far we want to clip for our advantage value in PPO\n",
      "/var/folders/d4/_v_lx6gx66z8htqrwxr89lvc0000gn/T/ipykernel_86005/3706438210.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'gae_lambda':trial.suggest_uniform('gae_lambda', 0.8, 0.99) # smoothing parameter (used when calculating advantage)\n",
      "[W 2024-11-04 00:21:22,612] Trial 0 failed with parameters: {'n_steps': 2744, 'gamma': 0.8779151472586653, 'learning_rate': 4.658266155214521e-05, 'clip_range': 0.36718642934780177, 'gae_lambda': 0.970603977599398} because of the following error: RuntimeError('Cannot create multiple emulator instances per process, make sure to call env.close() on each environment before creating a new one').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/suyogkhanal/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/d4/_v_lx6gx66z8htqrwxr89lvc0000gn/T/ipykernel_86005/1670576652.py\", line 7, in optimize_agent\n",
      "    env = StreetFighter()\n",
      "  File \"/var/folders/d4/_v_lx6gx66z8htqrwxr89lvc0000gn/T/ipykernel_86005/831802053.py\", line 11, in __init__\n",
      "    self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis', use_restricted_actions=retro.Actions.FILTERED) # used to get valid button combos\n",
      "  File \"/Users/suyogkhanal/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/retro/__init__.py\", line 55, in make\n",
      "    return RetroEnv(game, state, inttype=inttype, **kwargs)\n",
      "  File \"/Users/suyogkhanal/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/retro/retro_env.py\", line 87, in __init__\n",
      "    self.em = retro.RetroEmulator(rom_path)\n",
      "RuntimeError: Cannot create multiple emulator instances per process, make sure to call env.close() on each environment before creating a new one\n",
      "[W 2024-11-04 00:21:22,613] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot create multiple emulator instances per process, make sure to call env.close() on each environment before creating a new one",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Creating the experiment \u001b[39;00m\n\u001b[1;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# since mean reward is positive we maximize, otherwise minimize\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimize_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# for prod used n_trials=100\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[65], line 7\u001b[0m, in \u001b[0;36moptimize_agent\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      4\u001b[0m model_params \u001b[38;5;241m=\u001b[39m optimize_ppo(trial)  \u001b[38;5;66;03m# get dict of hyperparams\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create environment \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mStreetFighter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m env \u001b[38;5;241m=\u001b[39m Monitor(env, LOG_DIR) \u001b[38;5;66;03m# allowd for logging mean episode reward and mean episode length\u001b[39;00m\n\u001b[1;32m      9\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: env])\n",
      "Cell \u001b[0;32mIn[58], line 11\u001b[0m, in \u001b[0;36mStreetFighter.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menemy_health \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m144\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Startup and instance of the game \u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame \u001b[38;5;241m=\u001b[39m \u001b[43mretro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStreetFighterIISpecialChampionEdition-Genesis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_restricted_actions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mActions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFILTERED\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/retro/__init__.py:55\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(game, state, inttype, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGame not found: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Did you make sure to import the ROM?\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m game)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRetroEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minttype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minttype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/retro/retro_env.py:87\u001b[0m, in \u001b[0;36mRetroEnv.__init__\u001b[0;34m(self, game, state, scenario, info, use_restricted_actions, record, players, inttype, obs_type)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# We can't have more than one emulator per process. Before creating an\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# emulator, ensure that unused ones are garbage-collected\u001b[39;00m\n\u001b[1;32m     86\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mem \u001b[38;5;241m=\u001b[39m \u001b[43mretro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRetroEmulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrom_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mem\u001b[38;5;241m.\u001b[39mconfigure_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mem\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot create multiple emulator instances per process, make sure to call env.close() on each environment before creating a new one"
     ]
    }
   ],
   "source": [
    "# Creating the experiment \n",
    "study = optuna.create_study(direction='maximize') # since mean reward is positive we maximize, otherwise minimize\n",
    "study.optimize(optimize_agent, n_trials=1, n_jobs=1) # for prod used n_trials=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_steps': 7717,\n",
       " 'gamma': 0.8951474854534238,\n",
       " 'learning_rate': 1.5173785862671653e-05,\n",
       " 'clip_range': 0.13355095227019517,\n",
       " 'gae_lambda': 0.9181855173148512}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, state=TrialState.COMPLETE, values=[2000.0], datetime_start=datetime.datetime(2024, 10, 22, 1, 12, 54, 242354), datetime_complete=datetime.datetime(2024, 10, 22, 1, 14, 56, 805445), params={'n_steps': 7717, 'gamma': 0.8951474854534238, 'learning_rate': 1.5173785862671653e-05, 'clip_range': 0.13355095227019517, 'gae_lambda': 0.9181855173148512}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_steps': IntDistribution(high=8192, log=False, low=2048, step=1), 'gamma': FloatDistribution(high=0.9999, log=True, low=0.8, step=None), 'learning_rate': FloatDistribution(high=0.0001, log=True, low=1e-05, step=None), 'clip_range': FloatDistribution(high=0.4, log=False, low=0.1, step=None), 'gae_lambda': FloatDistribution(high=0.99, log=False, low=0.8, step=None)}, trial_id=0, value=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'opt/trial_0_best_model.zip.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOPT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrial_0_best_model.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py:680\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    678\u001b[0m     get_system_info()\n\u001b[0;32m--> 680\u001b[0m data, params, pytorch_variables \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo params found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:403\u001b[0m, in \u001b[0;36mload_from_zip_file\u001b[0;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_zip_file\u001b[39m(\n\u001b[1;32m    377\u001b[0m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath, io\u001b[38;5;241m.\u001b[39mBufferedIOBase],\n\u001b[1;32m    378\u001b[0m     load_data: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     print_system_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/functools.py:875\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    873\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:240\u001b[0m, in \u001b[0;36mopen_path_str\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;129m@open_path\u001b[39m\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m io\u001b[38;5;241m.\u001b[39mBufferedIOBase:\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    that the path exists.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:291\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    285\u001b[0m         path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# if opening was successful uses the open_path() function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:272\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    270\u001b[0m             path, suffix \u001b[38;5;241m=\u001b[39m newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:264\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m open_path(\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, mode, verbose, suffix)\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/pathlib.py:1221\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_closed()\n\u001b[0;32m-> 1221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m               \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/pathlib.py:1077\u001b[0m, in \u001b[0;36mPath._opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_opener\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, flags, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0o666\u001b[39m):\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;66;03m# A stub for the opener argument to built-in open()\u001b[39;00m\n\u001b[0;32m-> 1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'opt/trial_0_best_model.zip.zip'"
     ]
    }
   ],
   "source": [
    "model = PPO.load(os.path.join(OPT_DIR, 'trial_0_best_model.zip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base callback \n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback): # continuously learn by starting from best parameters done above\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "VecFrameStack only works with gym.spaces.Box and gym.spaces.Dict observation spaces",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m env \u001b[38;5;241m=\u001b[39m Monitor(env, LOG_DIR)\n\u001b[1;32m      4\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: env])\n\u001b[0;32m----> 5\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mVecFrameStack\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/stable_baselines3/common/vec_env/vec_frame_stack.py:22\u001b[0m, in \u001b[0;36mVecFrameStack.__init__\u001b[0;34m(self, venv, n_stack, channels_order)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, venv: VecEnv, n_stack: \u001b[38;5;28mint\u001b[39m, channels_order: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Mapping[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m     23\u001b[0m         venv\u001b[38;5;241m.\u001b[39mobservation_space, (spaces\u001b[38;5;241m.\u001b[39mBox, spaces\u001b[38;5;241m.\u001b[39mDict)\n\u001b[1;32m     24\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVecFrameStack only works with gym.spaces.Box and gym.spaces.Dict observation spaces\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstacked_obs \u001b[38;5;241m=\u001b[39m StackedObservations(venv\u001b[38;5;241m.\u001b[39mnum_envs, n_stack, venv\u001b[38;5;241m.\u001b[39mobservation_space, channels_order)\n\u001b[1;32m     27\u001b[0m     observation_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstacked_obs\u001b[38;5;241m.\u001b[39mstacked_observation_space\n",
      "\u001b[0;31mAssertionError\u001b[0m: VecFrameStack only works with gym.spaces.Box and gym.spaces.Dict observation spaces"
     ]
    }
   ],
   "source": [
    "# Create environment \n",
    "env = StreetFighter()\n",
    "env = Monitor(env, LOG_DIR)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_params \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params\u001b[49m\n\u001b[1;32m      2\u001b[0m model_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_steps\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7488\u001b[39m  \u001b[38;5;66;03m# set n_steps to 7488 or a factor of 64\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model_params['learning_rate'] = 5e-7 -> if really slow at training\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/optuna/study/study.py:119\u001b[0m, in \u001b[0;36mStudy.best_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbest_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return parameters of the best trial in the study.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_trial\u001b[49m\u001b[38;5;241m.\u001b[39mparams\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/optuna/study/study.py:162\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# If the trial with the best value is infeasible, select the best trial from all feasible\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# trials. Note that the behavior is undefined when constrained optimization without the\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# violation value in the best-valued trial.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m constraints \u001b[38;5;241m=\u001b[39m best_trial\u001b[38;5;241m.\u001b[39msystem_attrs\u001b[38;5;241m.\u001b[39mget(_CONSTRAINTS_KEY)\n",
      "File \u001b[0;32m~/Coding Projects/StreetFighterAI/.venv/lib/python3.8/site-packages/optuna/storages/_in_memory.py:232\u001b[0m, in \u001b[0;36mInMemoryStorage.get_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    229\u001b[0m best_trial_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mbest_trial_id\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_trial_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo trials are completed yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mdirections) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial can be obtained only for single-objective optimization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "model_params = study.best_params\n",
    "model_params['n_steps'] = 7488  # set n_steps to 7488 or a factor of 64\n",
    "# model_params['learning_rate'] = 5e-7 -> if really slow at training\n",
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCnnPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, env, tensorboard_log\u001b[38;5;241m=\u001b[39mLOG_DIR, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mmodel_params\u001b[49m) \u001b[38;5;66;03m# verbose 1 shows results as training\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_params' is not defined"
     ]
    }
   ],
   "source": [
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, **model_params) # verbose 1 shows results as training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Reload previous weights from HPO\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OPT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrial_0_best_model.zip\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Reload previous weights from HPO\n",
    "model.load(os.path.join(OPT_DIR, 'trial_0_best_model.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Kick off training \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, callback\u001b[38;5;241m=\u001b[39mcallback) \u001b[38;5;66;03m# timestep 5000000 recommended\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Kick off training \n",
    "model.learn(total_timesteps=5000, callback=callback) # timestep 5000000 recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=. \n",
    "# cd to logs\n",
    "# ^ use to visually see learning progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\StreetFighterRL\\env_3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:435: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  th_object = th.load(file_content, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load('./train/best_model_7000.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\StreetFighterRL\\env_3\\lib\\site-packages\\pyglet\\libs\\win32\\__init__.py:318: UserWarning: Could not set COM MTA mode. Unexpected behavior may occur.\n",
      "  warnings.warn(\"Could not set COM MTA mode. Unexpected behavior may occur.\")\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, render=True, n_eval_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5900.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(model.predict(obs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset game to starting state\n",
    "obs = env.reset()\n",
    "# Set flag to flase\n",
    "done = False\n",
    "for game in range(1): \n",
    "    while not done: \n",
    "        if done: \n",
    "            obs = env.reset()\n",
    "        env.render()\n",
    "        action = model.predict(obs)[0]\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        time.sleep(0.01)\n",
    "        print(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mucking aboyt.213213231112331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([[[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]], [[[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]\n",
      "\n",
      " [[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]\n",
      "\n",
      " [[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]\n",
      "\n",
      " [[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]\n",
      "\n",
      " [[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]], (84, 84, 1), uint8)\n"
     ]
    }
   ],
   "source": [
    "env = StreetFighter()\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# was on protobuf 5.28.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please note that pyglet 1.3.2 was for tensorboard, the rendering was for newesrt version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
